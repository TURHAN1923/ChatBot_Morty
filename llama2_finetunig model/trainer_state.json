{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0051934065276573,
  "eval_steps": 500,
  "global_step": 42000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011966374487689592,
      "grad_norm": 0.06541421264410019,
      "learning_rate": 0.000199926604919066,
      "loss": 2.859,
      "step": 50
    },
    {
      "epoch": 0.0023932748975379185,
      "grad_norm": 0.09520205110311508,
      "learning_rate": 0.00019984682765718118,
      "loss": 0.1476,
      "step": 100
    },
    {
      "epoch": 0.0035899123463068775,
      "grad_norm": 0.06984875351190567,
      "learning_rate": 0.00019976705039529636,
      "loss": 0.1053,
      "step": 150
    },
    {
      "epoch": 0.004786549795075837,
      "grad_norm": 0.07655277103185654,
      "learning_rate": 0.00019968727313341155,
      "loss": 0.1039,
      "step": 200
    },
    {
      "epoch": 0.005983187243844796,
      "grad_norm": 0.06163579970598221,
      "learning_rate": 0.00019960749587152673,
      "loss": 0.1026,
      "step": 250
    },
    {
      "epoch": 0.007179824692613755,
      "grad_norm": 0.08485342562198639,
      "learning_rate": 0.0001995277186096419,
      "loss": 0.0991,
      "step": 300
    },
    {
      "epoch": 0.008376462141382714,
      "grad_norm": 0.0666341558098793,
      "learning_rate": 0.00019944794134775707,
      "loss": 0.0934,
      "step": 350
    },
    {
      "epoch": 0.009573099590151674,
      "grad_norm": 0.08352573215961456,
      "learning_rate": 0.00019936816408587226,
      "loss": 0.0995,
      "step": 400
    },
    {
      "epoch": 0.010769737038920634,
      "grad_norm": 0.06700582802295685,
      "learning_rate": 0.00019928838682398744,
      "loss": 0.0953,
      "step": 450
    },
    {
      "epoch": 0.011966374487689592,
      "grad_norm": 0.06855334341526031,
      "learning_rate": 0.0001992086095621026,
      "loss": 0.0918,
      "step": 500
    },
    {
      "epoch": 0.013163011936458552,
      "grad_norm": 0.07564760744571686,
      "learning_rate": 0.00019912883230021778,
      "loss": 0.0964,
      "step": 550
    },
    {
      "epoch": 0.01435964938522751,
      "grad_norm": 0.0610971599817276,
      "learning_rate": 0.00019904905503833297,
      "loss": 0.0973,
      "step": 600
    },
    {
      "epoch": 0.01555628683399647,
      "grad_norm": 0.07779794931411743,
      "learning_rate": 0.00019896927777644815,
      "loss": 0.0958,
      "step": 650
    },
    {
      "epoch": 0.016752924282765428,
      "grad_norm": 0.058864742517471313,
      "learning_rate": 0.00019888950051456333,
      "loss": 0.0889,
      "step": 700
    },
    {
      "epoch": 0.017949561731534388,
      "grad_norm": 0.05721962824463844,
      "learning_rate": 0.00019880972325267852,
      "loss": 0.0959,
      "step": 750
    },
    {
      "epoch": 0.019146199180303348,
      "grad_norm": 0.06388098746538162,
      "learning_rate": 0.0001987299459907937,
      "loss": 0.096,
      "step": 800
    },
    {
      "epoch": 0.020342836629072308,
      "grad_norm": 0.04710838571190834,
      "learning_rate": 0.0001986501687289089,
      "loss": 0.0946,
      "step": 850
    },
    {
      "epoch": 0.021539474077841268,
      "grad_norm": 0.07803452014923096,
      "learning_rate": 0.00019857039146702407,
      "loss": 0.1003,
      "step": 900
    },
    {
      "epoch": 0.022736111526610224,
      "grad_norm": 0.05775423347949982,
      "learning_rate": 0.00019849061420513926,
      "loss": 0.0938,
      "step": 950
    },
    {
      "epoch": 0.023932748975379184,
      "grad_norm": 0.055391907691955566,
      "learning_rate": 0.00019841083694325444,
      "loss": 0.0993,
      "step": 1000
    },
    {
      "epoch": 0.025129386424148144,
      "grad_norm": 0.053979355841875076,
      "learning_rate": 0.00019833105968136962,
      "loss": 0.0912,
      "step": 1050
    },
    {
      "epoch": 0.026326023872917104,
      "grad_norm": 0.05584635213017464,
      "learning_rate": 0.0001982512824194848,
      "loss": 0.101,
      "step": 1100
    },
    {
      "epoch": 0.027522661321686064,
      "grad_norm": 0.0643095076084137,
      "learning_rate": 0.0001981715051576,
      "loss": 0.0908,
      "step": 1150
    },
    {
      "epoch": 0.02871929877045502,
      "grad_norm": 0.049992356449365616,
      "learning_rate": 0.00019809172789571518,
      "loss": 0.0956,
      "step": 1200
    },
    {
      "epoch": 0.02991593621922398,
      "grad_norm": 0.04925989359617233,
      "learning_rate": 0.00019801195063383036,
      "loss": 0.0944,
      "step": 1250
    },
    {
      "epoch": 0.03111257366799294,
      "grad_norm": 0.057812679558992386,
      "learning_rate": 0.00019793217337194554,
      "loss": 0.1012,
      "step": 1300
    },
    {
      "epoch": 0.032309211116761896,
      "grad_norm": 0.05271443352103233,
      "learning_rate": 0.00019785239611006073,
      "loss": 0.0912,
      "step": 1350
    },
    {
      "epoch": 0.033505848565530856,
      "grad_norm": 0.06075990945100784,
      "learning_rate": 0.0001977726188481759,
      "loss": 0.0897,
      "step": 1400
    },
    {
      "epoch": 0.034702486014299816,
      "grad_norm": 0.07791033387184143,
      "learning_rate": 0.0001976928415862911,
      "loss": 0.1011,
      "step": 1450
    },
    {
      "epoch": 0.035899123463068776,
      "grad_norm": 0.045221712440252304,
      "learning_rate": 0.00019761306432440628,
      "loss": 0.0932,
      "step": 1500
    },
    {
      "epoch": 0.037095760911837736,
      "grad_norm": 0.05630495026707649,
      "learning_rate": 0.00019753328706252147,
      "loss": 0.0983,
      "step": 1550
    },
    {
      "epoch": 0.038292398360606696,
      "grad_norm": 0.052288953214883804,
      "learning_rate": 0.00019745350980063665,
      "loss": 0.0985,
      "step": 1600
    },
    {
      "epoch": 0.039489035809375655,
      "grad_norm": 0.0539131835103035,
      "learning_rate": 0.0001973737325387518,
      "loss": 0.0983,
      "step": 1650
    },
    {
      "epoch": 0.040685673258144615,
      "grad_norm": 0.055419180542230606,
      "learning_rate": 0.000197293955276867,
      "loss": 0.0984,
      "step": 1700
    },
    {
      "epoch": 0.041882310706913575,
      "grad_norm": 0.05777228996157646,
      "learning_rate": 0.00019721417801498218,
      "loss": 0.0939,
      "step": 1750
    },
    {
      "epoch": 0.043078948155682535,
      "grad_norm": 0.03962264209985733,
      "learning_rate": 0.00019713440075309736,
      "loss": 0.0963,
      "step": 1800
    },
    {
      "epoch": 0.04427558560445149,
      "grad_norm": 0.054507628083229065,
      "learning_rate": 0.00019705462349121254,
      "loss": 0.0908,
      "step": 1850
    },
    {
      "epoch": 0.04547222305322045,
      "grad_norm": 0.057679325342178345,
      "learning_rate": 0.00019697484622932773,
      "loss": 0.0925,
      "step": 1900
    },
    {
      "epoch": 0.04666886050198941,
      "grad_norm": 0.03605522960424423,
      "learning_rate": 0.0001968950689674429,
      "loss": 0.0901,
      "step": 1950
    },
    {
      "epoch": 0.04786549795075837,
      "grad_norm": 0.05654224380850792,
      "learning_rate": 0.00019681529170555807,
      "loss": 0.0928,
      "step": 2000
    },
    {
      "epoch": 0.04906213539952733,
      "grad_norm": 0.04138633981347084,
      "learning_rate": 0.00019673551444367325,
      "loss": 0.088,
      "step": 2050
    },
    {
      "epoch": 0.05025877284829629,
      "grad_norm": 0.04897608608007431,
      "learning_rate": 0.00019665573718178844,
      "loss": 0.1007,
      "step": 2100
    },
    {
      "epoch": 0.05145541029706525,
      "grad_norm": 0.05662601441144943,
      "learning_rate": 0.00019657595991990362,
      "loss": 0.1002,
      "step": 2150
    },
    {
      "epoch": 0.05265204774583421,
      "grad_norm": 0.048548731952905655,
      "learning_rate": 0.0001964961826580188,
      "loss": 0.0896,
      "step": 2200
    },
    {
      "epoch": 0.05384868519460317,
      "grad_norm": 0.04843660816550255,
      "learning_rate": 0.000196416405396134,
      "loss": 0.0888,
      "step": 2250
    },
    {
      "epoch": 0.05504532264337213,
      "grad_norm": 0.04486289620399475,
      "learning_rate": 0.00019633662813424918,
      "loss": 0.0909,
      "step": 2300
    },
    {
      "epoch": 0.05624196009214109,
      "grad_norm": 0.044556114822626114,
      "learning_rate": 0.00019625685087236436,
      "loss": 0.0926,
      "step": 2350
    },
    {
      "epoch": 0.05743859754091004,
      "grad_norm": 0.040153954178094864,
      "learning_rate": 0.00019617707361047954,
      "loss": 0.0944,
      "step": 2400
    },
    {
      "epoch": 0.058635234989679,
      "grad_norm": 0.05567760393023491,
      "learning_rate": 0.00019609729634859473,
      "loss": 0.096,
      "step": 2450
    },
    {
      "epoch": 0.05983187243844796,
      "grad_norm": 0.040047165006399155,
      "learning_rate": 0.0001960175190867099,
      "loss": 0.1005,
      "step": 2500
    },
    {
      "epoch": 0.06102850988721692,
      "grad_norm": 0.04428526386618614,
      "learning_rate": 0.0001959377418248251,
      "loss": 0.0971,
      "step": 2550
    },
    {
      "epoch": 0.06222514733598588,
      "grad_norm": 0.041193995624780655,
      "learning_rate": 0.00019585796456294028,
      "loss": 0.0959,
      "step": 2600
    },
    {
      "epoch": 0.06342178478475484,
      "grad_norm": 0.05472981929779053,
      "learning_rate": 0.00019577818730105547,
      "loss": 0.0894,
      "step": 2650
    },
    {
      "epoch": 0.06461842223352379,
      "grad_norm": 0.04711853712797165,
      "learning_rate": 0.00019569841003917065,
      "loss": 0.094,
      "step": 2700
    },
    {
      "epoch": 0.06581505968229276,
      "grad_norm": 0.040996018797159195,
      "learning_rate": 0.00019561863277728583,
      "loss": 0.0933,
      "step": 2750
    },
    {
      "epoch": 0.06701169713106171,
      "grad_norm": 0.04833655059337616,
      "learning_rate": 0.00019553885551540102,
      "loss": 0.0933,
      "step": 2800
    },
    {
      "epoch": 0.06820833457983068,
      "grad_norm": 0.054447419941425323,
      "learning_rate": 0.0001954590782535162,
      "loss": 0.0918,
      "step": 2850
    },
    {
      "epoch": 0.06940497202859963,
      "grad_norm": 0.044757161289453506,
      "learning_rate": 0.0001953793009916314,
      "loss": 0.091,
      "step": 2900
    },
    {
      "epoch": 0.0706016094773686,
      "grad_norm": 0.0535990446805954,
      "learning_rate": 0.00019529952372974657,
      "loss": 0.0911,
      "step": 2950
    },
    {
      "epoch": 0.07179824692613755,
      "grad_norm": 0.05359784886240959,
      "learning_rate": 0.00019521974646786175,
      "loss": 0.0935,
      "step": 3000
    },
    {
      "epoch": 0.07299488437490652,
      "grad_norm": 0.04011470451951027,
      "learning_rate": 0.0001951399692059769,
      "loss": 0.0953,
      "step": 3050
    },
    {
      "epoch": 0.07419152182367547,
      "grad_norm": 0.043866053223609924,
      "learning_rate": 0.0001950601919440921,
      "loss": 0.0984,
      "step": 3100
    },
    {
      "epoch": 0.07538815927244442,
      "grad_norm": 0.04056064784526825,
      "learning_rate": 0.00019498041468220728,
      "loss": 0.0902,
      "step": 3150
    },
    {
      "epoch": 0.07658479672121339,
      "grad_norm": 0.04940652474761009,
      "learning_rate": 0.00019490063742032246,
      "loss": 0.0891,
      "step": 3200
    },
    {
      "epoch": 0.07778143416998234,
      "grad_norm": 0.04735073074698448,
      "learning_rate": 0.00019482086015843765,
      "loss": 0.0897,
      "step": 3250
    },
    {
      "epoch": 0.07897807161875131,
      "grad_norm": 0.08085121214389801,
      "learning_rate": 0.00019474108289655283,
      "loss": 0.0899,
      "step": 3300
    },
    {
      "epoch": 0.08017470906752026,
      "grad_norm": 0.058185137808322906,
      "learning_rate": 0.00019466130563466802,
      "loss": 0.0954,
      "step": 3350
    },
    {
      "epoch": 0.08137134651628923,
      "grad_norm": 0.04046263545751572,
      "learning_rate": 0.0001945815283727832,
      "loss": 0.0884,
      "step": 3400
    },
    {
      "epoch": 0.08256798396505818,
      "grad_norm": 0.05403339862823486,
      "learning_rate": 0.00019450175111089839,
      "loss": 0.0911,
      "step": 3450
    },
    {
      "epoch": 0.08376462141382715,
      "grad_norm": 0.044002436101436615,
      "learning_rate": 0.00019442197384901357,
      "loss": 0.0931,
      "step": 3500
    },
    {
      "epoch": 0.0849612588625961,
      "grad_norm": 0.04273013025522232,
      "learning_rate": 0.00019434219658712875,
      "loss": 0.0884,
      "step": 3550
    },
    {
      "epoch": 0.08615789631136507,
      "grad_norm": 0.05228099972009659,
      "learning_rate": 0.00019426241932524394,
      "loss": 0.0938,
      "step": 3600
    },
    {
      "epoch": 0.08735453376013402,
      "grad_norm": 0.04189521074295044,
      "learning_rate": 0.00019418264206335912,
      "loss": 0.0956,
      "step": 3650
    },
    {
      "epoch": 0.08855117120890298,
      "grad_norm": 0.05477125197649002,
      "learning_rate": 0.00019410286480147428,
      "loss": 0.0908,
      "step": 3700
    },
    {
      "epoch": 0.08974780865767194,
      "grad_norm": 0.041346050798892975,
      "learning_rate": 0.00019402308753958946,
      "loss": 0.095,
      "step": 3750
    },
    {
      "epoch": 0.0909444461064409,
      "grad_norm": 0.04183253273367882,
      "learning_rate": 0.00019394331027770465,
      "loss": 0.0939,
      "step": 3800
    },
    {
      "epoch": 0.09214108355520986,
      "grad_norm": 0.040156472474336624,
      "learning_rate": 0.00019386353301581983,
      "loss": 0.0914,
      "step": 3850
    },
    {
      "epoch": 0.09333772100397882,
      "grad_norm": 0.04858915135264397,
      "learning_rate": 0.00019378375575393502,
      "loss": 0.0912,
      "step": 3900
    },
    {
      "epoch": 0.09453435845274778,
      "grad_norm": 0.04198314622044563,
      "learning_rate": 0.0001937039784920502,
      "loss": 0.0929,
      "step": 3950
    },
    {
      "epoch": 0.09573099590151674,
      "grad_norm": 0.04807644337415695,
      "learning_rate": 0.00019362420123016539,
      "loss": 0.0889,
      "step": 4000
    },
    {
      "epoch": 0.0969276333502857,
      "grad_norm": 0.05327035114169121,
      "learning_rate": 0.00019354442396828057,
      "loss": 0.0934,
      "step": 4050
    },
    {
      "epoch": 0.09812427079905466,
      "grad_norm": 0.06207665055990219,
      "learning_rate": 0.00019346464670639575,
      "loss": 0.0925,
      "step": 4100
    },
    {
      "epoch": 0.09932090824782362,
      "grad_norm": 0.06094468757510185,
      "learning_rate": 0.00019338486944451094,
      "loss": 0.091,
      "step": 4150
    },
    {
      "epoch": 0.10051754569659258,
      "grad_norm": 0.03464026376605034,
      "learning_rate": 0.00019330509218262612,
      "loss": 0.0912,
      "step": 4200
    },
    {
      "epoch": 0.10171418314536153,
      "grad_norm": 0.03660445660352707,
      "learning_rate": 0.0001932253149207413,
      "loss": 0.0926,
      "step": 4250
    },
    {
      "epoch": 0.1029108205941305,
      "grad_norm": 0.04798892140388489,
      "learning_rate": 0.0001931455376588565,
      "loss": 0.0949,
      "step": 4300
    },
    {
      "epoch": 0.10410745804289945,
      "grad_norm": 0.042054854333400726,
      "learning_rate": 0.00019306576039697168,
      "loss": 0.0893,
      "step": 4350
    },
    {
      "epoch": 0.10530409549166841,
      "grad_norm": 0.035812679678201675,
      "learning_rate": 0.00019298598313508683,
      "loss": 0.0866,
      "step": 4400
    },
    {
      "epoch": 0.10650073294043737,
      "grad_norm": 0.03532978892326355,
      "learning_rate": 0.00019290620587320202,
      "loss": 0.0909,
      "step": 4450
    },
    {
      "epoch": 0.10769737038920633,
      "grad_norm": 0.04181062802672386,
      "learning_rate": 0.0001928264286113172,
      "loss": 0.0902,
      "step": 4500
    },
    {
      "epoch": 0.10889400783797529,
      "grad_norm": 0.04960884898900986,
      "learning_rate": 0.00019274665134943239,
      "loss": 0.0932,
      "step": 4550
    },
    {
      "epoch": 0.11009064528674425,
      "grad_norm": 0.04180578514933586,
      "learning_rate": 0.00019266687408754757,
      "loss": 0.0958,
      "step": 4600
    },
    {
      "epoch": 0.11128728273551321,
      "grad_norm": 0.05381695553660393,
      "learning_rate": 0.00019258709682566275,
      "loss": 0.09,
      "step": 4650
    },
    {
      "epoch": 0.11248392018428217,
      "grad_norm": 0.04178104177117348,
      "learning_rate": 0.00019250731956377794,
      "loss": 0.0921,
      "step": 4700
    },
    {
      "epoch": 0.11368055763305113,
      "grad_norm": 0.049447305500507355,
      "learning_rate": 0.00019242754230189312,
      "loss": 0.0922,
      "step": 4750
    },
    {
      "epoch": 0.11487719508182008,
      "grad_norm": 0.05188082531094551,
      "learning_rate": 0.0001923477650400083,
      "loss": 0.0918,
      "step": 4800
    },
    {
      "epoch": 0.11607383253058905,
      "grad_norm": 0.04135638475418091,
      "learning_rate": 0.0001922679877781235,
      "loss": 0.0928,
      "step": 4850
    },
    {
      "epoch": 0.117270469979358,
      "grad_norm": 0.050038281828165054,
      "learning_rate": 0.00019218821051623867,
      "loss": 0.086,
      "step": 4900
    },
    {
      "epoch": 0.11846710742812697,
      "grad_norm": 0.03649717941880226,
      "learning_rate": 0.00019210843325435386,
      "loss": 0.09,
      "step": 4950
    },
    {
      "epoch": 0.11966374487689592,
      "grad_norm": 0.06065363064408302,
      "learning_rate": 0.00019202865599246904,
      "loss": 0.0936,
      "step": 5000
    },
    {
      "epoch": 0.12086038232566489,
      "grad_norm": 0.04214690253138542,
      "learning_rate": 0.00019194887873058423,
      "loss": 0.0905,
      "step": 5050
    },
    {
      "epoch": 0.12205701977443384,
      "grad_norm": 0.039919402450323105,
      "learning_rate": 0.0001918691014686994,
      "loss": 0.096,
      "step": 5100
    },
    {
      "epoch": 0.1232536572232028,
      "grad_norm": 0.060489118099212646,
      "learning_rate": 0.0001917893242068146,
      "loss": 0.0922,
      "step": 5150
    },
    {
      "epoch": 0.12445029467197176,
      "grad_norm": 0.036683522164821625,
      "learning_rate": 0.00019170954694492978,
      "loss": 0.0893,
      "step": 5200
    },
    {
      "epoch": 0.1256469321207407,
      "grad_norm": 0.05261564254760742,
      "learning_rate": 0.00019162976968304496,
      "loss": 0.0904,
      "step": 5250
    },
    {
      "epoch": 0.12684356956950968,
      "grad_norm": 0.03669867292046547,
      "learning_rate": 0.00019154999242116015,
      "loss": 0.0921,
      "step": 5300
    },
    {
      "epoch": 0.12804020701827865,
      "grad_norm": 0.03464511036872864,
      "learning_rate": 0.00019147021515927533,
      "loss": 0.0894,
      "step": 5350
    },
    {
      "epoch": 0.12923684446704758,
      "grad_norm": 0.05562956631183624,
      "learning_rate": 0.0001913904378973905,
      "loss": 0.0911,
      "step": 5400
    },
    {
      "epoch": 0.13043348191581655,
      "grad_norm": 0.05587722361087799,
      "learning_rate": 0.00019131066063550567,
      "loss": 0.1008,
      "step": 5450
    },
    {
      "epoch": 0.13163011936458552,
      "grad_norm": 0.06440593302249908,
      "learning_rate": 0.00019123088337362086,
      "loss": 0.0915,
      "step": 5500
    },
    {
      "epoch": 0.13282675681335449,
      "grad_norm": 0.04919327050447464,
      "learning_rate": 0.00019115110611173604,
      "loss": 0.0862,
      "step": 5550
    },
    {
      "epoch": 0.13402339426212342,
      "grad_norm": 0.037143293768167496,
      "learning_rate": 0.00019107132884985123,
      "loss": 0.0906,
      "step": 5600
    },
    {
      "epoch": 0.1352200317108924,
      "grad_norm": 0.04414377361536026,
      "learning_rate": 0.0001909915515879664,
      "loss": 0.0927,
      "step": 5650
    },
    {
      "epoch": 0.13641666915966136,
      "grad_norm": 0.03814389929175377,
      "learning_rate": 0.0001909117743260816,
      "loss": 0.0882,
      "step": 5700
    },
    {
      "epoch": 0.13761330660843032,
      "grad_norm": 0.04431023821234703,
      "learning_rate": 0.00019083199706419675,
      "loss": 0.0924,
      "step": 5750
    },
    {
      "epoch": 0.13880994405719926,
      "grad_norm": 0.04518836364150047,
      "learning_rate": 0.00019075221980231194,
      "loss": 0.0895,
      "step": 5800
    },
    {
      "epoch": 0.14000658150596823,
      "grad_norm": 0.03911101073026657,
      "learning_rate": 0.00019067244254042712,
      "loss": 0.0859,
      "step": 5850
    },
    {
      "epoch": 0.1412032189547372,
      "grad_norm": 0.04559464380145073,
      "learning_rate": 0.0001905926652785423,
      "loss": 0.0912,
      "step": 5900
    },
    {
      "epoch": 0.14239985640350614,
      "grad_norm": 0.04701124131679535,
      "learning_rate": 0.0001905128880166575,
      "loss": 0.0904,
      "step": 5950
    },
    {
      "epoch": 0.1435964938522751,
      "grad_norm": 0.05227406695485115,
      "learning_rate": 0.00019043311075477267,
      "loss": 0.0927,
      "step": 6000
    },
    {
      "epoch": 0.14479313130104407,
      "grad_norm": 0.04544103518128395,
      "learning_rate": 0.00019035333349288786,
      "loss": 0.0899,
      "step": 6050
    },
    {
      "epoch": 0.14598976874981304,
      "grad_norm": 0.0430435948073864,
      "learning_rate": 0.00019027355623100304,
      "loss": 0.0847,
      "step": 6100
    },
    {
      "epoch": 0.14718640619858198,
      "grad_norm": 0.0413733571767807,
      "learning_rate": 0.00019019377896911823,
      "loss": 0.0884,
      "step": 6150
    },
    {
      "epoch": 0.14838304364735094,
      "grad_norm": 0.047305796295404434,
      "learning_rate": 0.0001901140017072334,
      "loss": 0.089,
      "step": 6200
    },
    {
      "epoch": 0.1495796810961199,
      "grad_norm": 0.044598840177059174,
      "learning_rate": 0.0001900342244453486,
      "loss": 0.0943,
      "step": 6250
    },
    {
      "epoch": 0.15077631854488885,
      "grad_norm": 0.0439944863319397,
      "learning_rate": 0.00018995444718346378,
      "loss": 0.0897,
      "step": 6300
    },
    {
      "epoch": 0.15197295599365782,
      "grad_norm": 0.04366070032119751,
      "learning_rate": 0.00018987466992157896,
      "loss": 0.0898,
      "step": 6350
    },
    {
      "epoch": 0.15316959344242678,
      "grad_norm": 0.04108285903930664,
      "learning_rate": 0.00018979489265969415,
      "loss": 0.0881,
      "step": 6400
    },
    {
      "epoch": 0.15436623089119575,
      "grad_norm": 0.04897872358560562,
      "learning_rate": 0.00018971511539780933,
      "loss": 0.0902,
      "step": 6450
    },
    {
      "epoch": 0.1555628683399647,
      "grad_norm": 0.049229905009269714,
      "learning_rate": 0.00018963533813592452,
      "loss": 0.0924,
      "step": 6500
    },
    {
      "epoch": 0.15675950578873366,
      "grad_norm": 0.04702761396765709,
      "learning_rate": 0.0001895555608740397,
      "loss": 0.096,
      "step": 6550
    },
    {
      "epoch": 0.15795614323750262,
      "grad_norm": 0.053470540791749954,
      "learning_rate": 0.00018947578361215488,
      "loss": 0.0876,
      "step": 6600
    },
    {
      "epoch": 0.1591527806862716,
      "grad_norm": 0.04904218390583992,
      "learning_rate": 0.00018939600635027007,
      "loss": 0.09,
      "step": 6650
    },
    {
      "epoch": 0.16034941813504053,
      "grad_norm": 0.03551933541893959,
      "learning_rate": 0.00018931622908838525,
      "loss": 0.0898,
      "step": 6700
    },
    {
      "epoch": 0.1615460555838095,
      "grad_norm": 0.03392834588885307,
      "learning_rate": 0.00018923645182650044,
      "loss": 0.093,
      "step": 6750
    },
    {
      "epoch": 0.16274269303257846,
      "grad_norm": 0.04114280268549919,
      "learning_rate": 0.00018915667456461562,
      "loss": 0.092,
      "step": 6800
    },
    {
      "epoch": 0.1639393304813474,
      "grad_norm": 0.04339584708213806,
      "learning_rate": 0.0001890768973027308,
      "loss": 0.0901,
      "step": 6850
    },
    {
      "epoch": 0.16513596793011637,
      "grad_norm": 0.04148893430829048,
      "learning_rate": 0.00018899712004084596,
      "loss": 0.0851,
      "step": 6900
    },
    {
      "epoch": 0.16633260537888533,
      "grad_norm": 0.03530026227235794,
      "learning_rate": 0.00018891734277896115,
      "loss": 0.0923,
      "step": 6950
    },
    {
      "epoch": 0.1675292428276543,
      "grad_norm": 0.03992393985390663,
      "learning_rate": 0.00018883756551707633,
      "loss": 0.0953,
      "step": 7000
    },
    {
      "epoch": 0.16872588027642324,
      "grad_norm": 0.05184107646346092,
      "learning_rate": 0.00018875778825519152,
      "loss": 0.0923,
      "step": 7050
    },
    {
      "epoch": 0.1699225177251922,
      "grad_norm": 0.04719800129532814,
      "learning_rate": 0.00018867801099330667,
      "loss": 0.091,
      "step": 7100
    },
    {
      "epoch": 0.17111915517396117,
      "grad_norm": 0.03620738536119461,
      "learning_rate": 0.00018859823373142186,
      "loss": 0.0896,
      "step": 7150
    },
    {
      "epoch": 0.17231579262273014,
      "grad_norm": 0.04691420868039131,
      "learning_rate": 0.00018851845646953704,
      "loss": 0.0925,
      "step": 7200
    },
    {
      "epoch": 0.17351243007149908,
      "grad_norm": 0.039261460304260254,
      "learning_rate": 0.00018843867920765223,
      "loss": 0.0936,
      "step": 7250
    },
    {
      "epoch": 0.17470906752026805,
      "grad_norm": 0.04402560368180275,
      "learning_rate": 0.0001883589019457674,
      "loss": 0.0866,
      "step": 7300
    },
    {
      "epoch": 0.175905704969037,
      "grad_norm": 0.05403511971235275,
      "learning_rate": 0.0001882791246838826,
      "loss": 0.0868,
      "step": 7350
    },
    {
      "epoch": 0.17710234241780595,
      "grad_norm": 0.04573977738618851,
      "learning_rate": 0.00018819934742199778,
      "loss": 0.0877,
      "step": 7400
    },
    {
      "epoch": 0.17829897986657492,
      "grad_norm": 0.046758655458688736,
      "learning_rate": 0.00018811957016011296,
      "loss": 0.0889,
      "step": 7450
    },
    {
      "epoch": 0.17949561731534389,
      "grad_norm": 0.06776638329029083,
      "learning_rate": 0.00018803979289822815,
      "loss": 0.0904,
      "step": 7500
    },
    {
      "epoch": 0.18069225476411285,
      "grad_norm": 0.044203970581293106,
      "learning_rate": 0.00018796001563634333,
      "loss": 0.0884,
      "step": 7550
    },
    {
      "epoch": 0.1818888922128818,
      "grad_norm": 0.03760308399796486,
      "learning_rate": 0.00018788023837445852,
      "loss": 0.0946,
      "step": 7600
    },
    {
      "epoch": 0.18308552966165076,
      "grad_norm": 0.0327487587928772,
      "learning_rate": 0.0001878004611125737,
      "loss": 0.0945,
      "step": 7650
    },
    {
      "epoch": 0.18428216711041973,
      "grad_norm": 0.04194552078843117,
      "learning_rate": 0.00018772068385068888,
      "loss": 0.0936,
      "step": 7700
    },
    {
      "epoch": 0.1854788045591887,
      "grad_norm": 0.05425315722823143,
      "learning_rate": 0.00018764090658880407,
      "loss": 0.0968,
      "step": 7750
    },
    {
      "epoch": 0.18667544200795763,
      "grad_norm": 0.04189480096101761,
      "learning_rate": 0.00018756112932691925,
      "loss": 0.0906,
      "step": 7800
    },
    {
      "epoch": 0.1878720794567266,
      "grad_norm": 0.044938430190086365,
      "learning_rate": 0.00018748135206503444,
      "loss": 0.0905,
      "step": 7850
    },
    {
      "epoch": 0.18906871690549557,
      "grad_norm": 0.032668907195329666,
      "learning_rate": 0.00018740157480314962,
      "loss": 0.0867,
      "step": 7900
    },
    {
      "epoch": 0.1902653543542645,
      "grad_norm": 0.05102011561393738,
      "learning_rate": 0.0001873217975412648,
      "loss": 0.0907,
      "step": 7950
    },
    {
      "epoch": 0.19146199180303347,
      "grad_norm": 0.03872739151120186,
      "learning_rate": 0.00018724202027938,
      "loss": 0.0923,
      "step": 8000
    },
    {
      "epoch": 0.19265862925180244,
      "grad_norm": 0.03738268092274666,
      "learning_rate": 0.00018716224301749517,
      "loss": 0.086,
      "step": 8050
    },
    {
      "epoch": 0.1938552667005714,
      "grad_norm": 0.039911817759275436,
      "learning_rate": 0.00018708246575561036,
      "loss": 0.0938,
      "step": 8100
    },
    {
      "epoch": 0.19505190414934034,
      "grad_norm": 0.0423705093562603,
      "learning_rate": 0.00018700268849372554,
      "loss": 0.0898,
      "step": 8150
    },
    {
      "epoch": 0.1962485415981093,
      "grad_norm": 0.035624876618385315,
      "learning_rate": 0.00018692291123184073,
      "loss": 0.089,
      "step": 8200
    },
    {
      "epoch": 0.19744517904687828,
      "grad_norm": 0.0421474315226078,
      "learning_rate": 0.00018684313396995588,
      "loss": 0.0949,
      "step": 8250
    },
    {
      "epoch": 0.19864181649564724,
      "grad_norm": 0.05440942198038101,
      "learning_rate": 0.00018676335670807107,
      "loss": 0.0913,
      "step": 8300
    },
    {
      "epoch": 0.19983845394441618,
      "grad_norm": 0.038931265473365784,
      "learning_rate": 0.00018668357944618625,
      "loss": 0.0907,
      "step": 8350
    },
    {
      "epoch": 0.20103509139318515,
      "grad_norm": 0.03587690368294716,
      "learning_rate": 0.00018660380218430144,
      "loss": 0.0918,
      "step": 8400
    },
    {
      "epoch": 0.20223172884195412,
      "grad_norm": 0.03469247370958328,
      "learning_rate": 0.00018652402492241662,
      "loss": 0.0937,
      "step": 8450
    },
    {
      "epoch": 0.20342836629072306,
      "grad_norm": 0.05501788854598999,
      "learning_rate": 0.0001864442476605318,
      "loss": 0.0923,
      "step": 8500
    },
    {
      "epoch": 0.20462500373949202,
      "grad_norm": 0.056026194244623184,
      "learning_rate": 0.000186364470398647,
      "loss": 0.0922,
      "step": 8550
    },
    {
      "epoch": 0.205821641188261,
      "grad_norm": 0.03588459640741348,
      "learning_rate": 0.00018628469313676217,
      "loss": 0.0916,
      "step": 8600
    },
    {
      "epoch": 0.20701827863702996,
      "grad_norm": 0.048217978328466415,
      "learning_rate": 0.00018620491587487736,
      "loss": 0.0881,
      "step": 8650
    },
    {
      "epoch": 0.2082149160857989,
      "grad_norm": 0.043371379375457764,
      "learning_rate": 0.00018612513861299254,
      "loss": 0.0946,
      "step": 8700
    },
    {
      "epoch": 0.20941155353456786,
      "grad_norm": 0.05150335654616356,
      "learning_rate": 0.0001860453613511077,
      "loss": 0.087,
      "step": 8750
    },
    {
      "epoch": 0.21060819098333683,
      "grad_norm": 0.040160633623600006,
      "learning_rate": 0.00018596558408922288,
      "loss": 0.0916,
      "step": 8800
    },
    {
      "epoch": 0.2118048284321058,
      "grad_norm": 0.04641289636492729,
      "learning_rate": 0.00018588580682733807,
      "loss": 0.0887,
      "step": 8850
    },
    {
      "epoch": 0.21300146588087474,
      "grad_norm": 0.05957219377160072,
      "learning_rate": 0.00018580602956545325,
      "loss": 0.088,
      "step": 8900
    },
    {
      "epoch": 0.2141981033296437,
      "grad_norm": 0.04631827026605606,
      "learning_rate": 0.00018572625230356844,
      "loss": 0.0937,
      "step": 8950
    },
    {
      "epoch": 0.21539474077841267,
      "grad_norm": 0.04246942326426506,
      "learning_rate": 0.00018564647504168362,
      "loss": 0.0875,
      "step": 9000
    },
    {
      "epoch": 0.2165913782271816,
      "grad_norm": 0.049767158925533295,
      "learning_rate": 0.0001855666977797988,
      "loss": 0.0961,
      "step": 9050
    },
    {
      "epoch": 0.21778801567595057,
      "grad_norm": 0.04730909317731857,
      "learning_rate": 0.000185486920517914,
      "loss": 0.0941,
      "step": 9100
    },
    {
      "epoch": 0.21898465312471954,
      "grad_norm": 0.04399699345231056,
      "learning_rate": 0.00018540714325602917,
      "loss": 0.0905,
      "step": 9150
    },
    {
      "epoch": 0.2201812905734885,
      "grad_norm": 0.04269109666347504,
      "learning_rate": 0.00018532736599414436,
      "loss": 0.0923,
      "step": 9200
    },
    {
      "epoch": 0.22137792802225745,
      "grad_norm": 0.040037356317043304,
      "learning_rate": 0.00018524758873225954,
      "loss": 0.091,
      "step": 9250
    },
    {
      "epoch": 0.22257456547102641,
      "grad_norm": 0.04299892857670784,
      "learning_rate": 0.00018516781147037473,
      "loss": 0.0926,
      "step": 9300
    },
    {
      "epoch": 0.22377120291979538,
      "grad_norm": 0.07542242854833603,
      "learning_rate": 0.0001850880342084899,
      "loss": 0.0908,
      "step": 9350
    },
    {
      "epoch": 0.22496784036856435,
      "grad_norm": 0.03621189668774605,
      "learning_rate": 0.0001850082569466051,
      "loss": 0.09,
      "step": 9400
    },
    {
      "epoch": 0.2261644778173333,
      "grad_norm": 0.043931495398283005,
      "learning_rate": 0.00018492847968472028,
      "loss": 0.0869,
      "step": 9450
    },
    {
      "epoch": 0.22736111526610225,
      "grad_norm": 0.0559869222342968,
      "learning_rate": 0.00018484870242283546,
      "loss": 0.0883,
      "step": 9500
    },
    {
      "epoch": 0.22855775271487122,
      "grad_norm": 0.044346507638692856,
      "learning_rate": 0.00018476892516095065,
      "loss": 0.0903,
      "step": 9550
    },
    {
      "epoch": 0.22975439016364016,
      "grad_norm": 0.043864667415618896,
      "learning_rate": 0.00018468914789906583,
      "loss": 0.0843,
      "step": 9600
    },
    {
      "epoch": 0.23095102761240913,
      "grad_norm": 0.044798530638217926,
      "learning_rate": 0.000184609370637181,
      "loss": 0.0904,
      "step": 9650
    },
    {
      "epoch": 0.2321476650611781,
      "grad_norm": 0.04293665289878845,
      "learning_rate": 0.00018452959337529617,
      "loss": 0.0904,
      "step": 9700
    },
    {
      "epoch": 0.23334430250994706,
      "grad_norm": 0.04816349595785141,
      "learning_rate": 0.00018444981611341136,
      "loss": 0.0931,
      "step": 9750
    },
    {
      "epoch": 0.234540939958716,
      "grad_norm": 0.04636422172188759,
      "learning_rate": 0.00018437003885152654,
      "loss": 0.0981,
      "step": 9800
    },
    {
      "epoch": 0.23573757740748497,
      "grad_norm": 0.0446118600666523,
      "learning_rate": 0.00018429026158964172,
      "loss": 0.089,
      "step": 9850
    },
    {
      "epoch": 0.23693421485625393,
      "grad_norm": 0.04823973402380943,
      "learning_rate": 0.0001842104843277569,
      "loss": 0.0889,
      "step": 9900
    },
    {
      "epoch": 0.23813085230502287,
      "grad_norm": 0.04653693363070488,
      "learning_rate": 0.0001841307070658721,
      "loss": 0.0887,
      "step": 9950
    },
    {
      "epoch": 0.23932748975379184,
      "grad_norm": 0.03435457870364189,
      "learning_rate": 0.00018405092980398728,
      "loss": 0.0941,
      "step": 10000
    },
    {
      "epoch": 0.2405241272025608,
      "grad_norm": 0.061526358127593994,
      "learning_rate": 0.00018397115254210246,
      "loss": 0.0878,
      "step": 10050
    },
    {
      "epoch": 0.24172076465132977,
      "grad_norm": 0.04574550315737724,
      "learning_rate": 0.00018389137528021765,
      "loss": 0.0908,
      "step": 10100
    },
    {
      "epoch": 0.2429174021000987,
      "grad_norm": 0.0438457615673542,
      "learning_rate": 0.00018381159801833283,
      "loss": 0.0889,
      "step": 10150
    },
    {
      "epoch": 0.24411403954886768,
      "grad_norm": 0.055142972618341446,
      "learning_rate": 0.00018373182075644801,
      "loss": 0.0905,
      "step": 10200
    },
    {
      "epoch": 0.24531067699763665,
      "grad_norm": 0.08579481393098831,
      "learning_rate": 0.0001836520434945632,
      "loss": 0.0942,
      "step": 10250
    },
    {
      "epoch": 0.2465073144464056,
      "grad_norm": 0.04366802051663399,
      "learning_rate": 0.00018357226623267838,
      "loss": 0.0912,
      "step": 10300
    },
    {
      "epoch": 0.24770395189517455,
      "grad_norm": 0.042881835252046585,
      "learning_rate": 0.00018349248897079357,
      "loss": 0.0937,
      "step": 10350
    },
    {
      "epoch": 0.24890058934394352,
      "grad_norm": 0.04069077596068382,
      "learning_rate": 0.00018341271170890875,
      "loss": 0.0815,
      "step": 10400
    },
    {
      "epoch": 0.25009722679271246,
      "grad_norm": 0.04439928010106087,
      "learning_rate": 0.0001833329344470239,
      "loss": 0.0892,
      "step": 10450
    },
    {
      "epoch": 0.2512938642414814,
      "grad_norm": 0.055238135159015656,
      "learning_rate": 0.0001832531571851391,
      "loss": 0.0883,
      "step": 10500
    },
    {
      "epoch": 0.2524905016902504,
      "grad_norm": 0.05380425602197647,
      "learning_rate": 0.00018317337992325428,
      "loss": 0.0921,
      "step": 10550
    },
    {
      "epoch": 0.25368713913901936,
      "grad_norm": 0.046911414712667465,
      "learning_rate": 0.00018309360266136946,
      "loss": 0.0932,
      "step": 10600
    },
    {
      "epoch": 0.2548837765877883,
      "grad_norm": 0.06413968652486801,
      "learning_rate": 0.00018301382539948465,
      "loss": 0.0921,
      "step": 10650
    },
    {
      "epoch": 0.2560804140365573,
      "grad_norm": 0.044430799782276154,
      "learning_rate": 0.00018293404813759983,
      "loss": 0.0853,
      "step": 10700
    },
    {
      "epoch": 0.25727705148532626,
      "grad_norm": 0.037135783582925797,
      "learning_rate": 0.00018285427087571501,
      "loss": 0.0869,
      "step": 10750
    },
    {
      "epoch": 0.25847368893409517,
      "grad_norm": 0.05888332426548004,
      "learning_rate": 0.0001827744936138302,
      "loss": 0.0888,
      "step": 10800
    },
    {
      "epoch": 0.25967032638286414,
      "grad_norm": 0.04150423780083656,
      "learning_rate": 0.00018269471635194538,
      "loss": 0.0943,
      "step": 10850
    },
    {
      "epoch": 0.2608669638316331,
      "grad_norm": 0.03859289735555649,
      "learning_rate": 0.00018261493909006057,
      "loss": 0.0878,
      "step": 10900
    },
    {
      "epoch": 0.26206360128040207,
      "grad_norm": 0.05205395817756653,
      "learning_rate": 0.00018253516182817575,
      "loss": 0.0924,
      "step": 10950
    },
    {
      "epoch": 0.26326023872917104,
      "grad_norm": 0.06401963531970978,
      "learning_rate": 0.0001824553845662909,
      "loss": 0.0908,
      "step": 11000
    },
    {
      "epoch": 0.26445687617794,
      "grad_norm": 0.05104149878025055,
      "learning_rate": 0.0001823756073044061,
      "loss": 0.0861,
      "step": 11050
    },
    {
      "epoch": 0.26565351362670897,
      "grad_norm": 0.04986567050218582,
      "learning_rate": 0.00018229583004252128,
      "loss": 0.0964,
      "step": 11100
    },
    {
      "epoch": 0.2668501510754779,
      "grad_norm": 0.049327313899993896,
      "learning_rate": 0.00018221605278063646,
      "loss": 0.0927,
      "step": 11150
    },
    {
      "epoch": 0.26804678852424685,
      "grad_norm": 0.05104224383831024,
      "learning_rate": 0.00018213627551875165,
      "loss": 0.0913,
      "step": 11200
    },
    {
      "epoch": 0.2692434259730158,
      "grad_norm": 0.047243230044841766,
      "learning_rate": 0.00018205649825686683,
      "loss": 0.0863,
      "step": 11250
    },
    {
      "epoch": 0.2704400634217848,
      "grad_norm": 0.039957255125045776,
      "learning_rate": 0.00018197672099498201,
      "loss": 0.0952,
      "step": 11300
    },
    {
      "epoch": 0.27163670087055375,
      "grad_norm": 0.051271338015794754,
      "learning_rate": 0.0001818969437330972,
      "loss": 0.0882,
      "step": 11350
    },
    {
      "epoch": 0.2728333383193227,
      "grad_norm": 0.037262167781591415,
      "learning_rate": 0.00018181716647121238,
      "loss": 0.0899,
      "step": 11400
    },
    {
      "epoch": 0.2740299757680917,
      "grad_norm": 0.055812984704971313,
      "learning_rate": 0.00018173738920932757,
      "loss": 0.0933,
      "step": 11450
    },
    {
      "epoch": 0.27522661321686065,
      "grad_norm": 0.03256867453455925,
      "learning_rate": 0.00018165761194744275,
      "loss": 0.0888,
      "step": 11500
    },
    {
      "epoch": 0.27642325066562956,
      "grad_norm": 0.05687487870454788,
      "learning_rate": 0.00018157783468555793,
      "loss": 0.0905,
      "step": 11550
    },
    {
      "epoch": 0.2776198881143985,
      "grad_norm": 0.03904777020215988,
      "learning_rate": 0.00018149805742367312,
      "loss": 0.0881,
      "step": 11600
    },
    {
      "epoch": 0.2788165255631675,
      "grad_norm": 0.06297741085290909,
      "learning_rate": 0.0001814182801617883,
      "loss": 0.0907,
      "step": 11650
    },
    {
      "epoch": 0.28001316301193646,
      "grad_norm": 0.06196290999650955,
      "learning_rate": 0.0001813385028999035,
      "loss": 0.0967,
      "step": 11700
    },
    {
      "epoch": 0.28120980046070543,
      "grad_norm": 0.03700488060712814,
      "learning_rate": 0.00018125872563801867,
      "loss": 0.0889,
      "step": 11750
    },
    {
      "epoch": 0.2824064379094744,
      "grad_norm": 0.04432515799999237,
      "learning_rate": 0.00018117894837613386,
      "loss": 0.0898,
      "step": 11800
    },
    {
      "epoch": 0.28360307535824336,
      "grad_norm": 0.03850163146853447,
      "learning_rate": 0.00018109917111424904,
      "loss": 0.0869,
      "step": 11850
    },
    {
      "epoch": 0.2847997128070123,
      "grad_norm": 0.056698888540267944,
      "learning_rate": 0.00018101939385236422,
      "loss": 0.0937,
      "step": 11900
    },
    {
      "epoch": 0.28599635025578124,
      "grad_norm": 0.048479899764060974,
      "learning_rate": 0.0001809396165904794,
      "loss": 0.0892,
      "step": 11950
    },
    {
      "epoch": 0.2871929877045502,
      "grad_norm": 0.05818243324756622,
      "learning_rate": 0.0001808598393285946,
      "loss": 0.0943,
      "step": 12000
    },
    {
      "epoch": 0.2883896251533192,
      "grad_norm": 0.05551178753376007,
      "learning_rate": 0.00018078006206670978,
      "loss": 0.0918,
      "step": 12050
    },
    {
      "epoch": 0.28958626260208814,
      "grad_norm": 0.05399007722735405,
      "learning_rate": 0.00018070028480482493,
      "loss": 0.0903,
      "step": 12100
    },
    {
      "epoch": 0.2907829000508571,
      "grad_norm": 0.05014035478234291,
      "learning_rate": 0.00018062050754294012,
      "loss": 0.0899,
      "step": 12150
    },
    {
      "epoch": 0.2919795374996261,
      "grad_norm": 0.05201489478349686,
      "learning_rate": 0.0001805407302810553,
      "loss": 0.0878,
      "step": 12200
    },
    {
      "epoch": 0.293176174948395,
      "grad_norm": 0.050728801637887955,
      "learning_rate": 0.0001804609530191705,
      "loss": 0.0913,
      "step": 12250
    },
    {
      "epoch": 0.29437281239716395,
      "grad_norm": 0.05432794243097305,
      "learning_rate": 0.00018038117575728567,
      "loss": 0.0866,
      "step": 12300
    },
    {
      "epoch": 0.2955694498459329,
      "grad_norm": 0.04599900543689728,
      "learning_rate": 0.00018030139849540083,
      "loss": 0.0926,
      "step": 12350
    },
    {
      "epoch": 0.2967660872947019,
      "grad_norm": 0.0539131723344326,
      "learning_rate": 0.000180221621233516,
      "loss": 0.0918,
      "step": 12400
    },
    {
      "epoch": 0.29796272474347085,
      "grad_norm": 0.06314975768327713,
      "learning_rate": 0.0001801418439716312,
      "loss": 0.0928,
      "step": 12450
    },
    {
      "epoch": 0.2991593621922398,
      "grad_norm": 0.04415516555309296,
      "learning_rate": 0.00018006206670974638,
      "loss": 0.0851,
      "step": 12500
    },
    {
      "epoch": 0.3003559996410088,
      "grad_norm": 0.0435645766556263,
      "learning_rate": 0.00017998228944786157,
      "loss": 0.0906,
      "step": 12550
    },
    {
      "epoch": 0.3015526370897777,
      "grad_norm": 0.04259102791547775,
      "learning_rate": 0.00017990251218597675,
      "loss": 0.0917,
      "step": 12600
    },
    {
      "epoch": 0.30274927453854666,
      "grad_norm": 0.03050272725522518,
      "learning_rate": 0.00017982273492409193,
      "loss": 0.0869,
      "step": 12650
    },
    {
      "epoch": 0.30394591198731563,
      "grad_norm": 0.05271882191300392,
      "learning_rate": 0.00017974295766220712,
      "loss": 0.0895,
      "step": 12700
    },
    {
      "epoch": 0.3051425494360846,
      "grad_norm": 0.05814271792769432,
      "learning_rate": 0.0001796631804003223,
      "loss": 0.09,
      "step": 12750
    },
    {
      "epoch": 0.30633918688485356,
      "grad_norm": 0.038827620446681976,
      "learning_rate": 0.0001795834031384375,
      "loss": 0.0855,
      "step": 12800
    },
    {
      "epoch": 0.30753582433362253,
      "grad_norm": 0.046489302068948746,
      "learning_rate": 0.00017950362587655267,
      "loss": 0.0911,
      "step": 12850
    },
    {
      "epoch": 0.3087324617823915,
      "grad_norm": 0.040495164692401886,
      "learning_rate": 0.00017942384861466786,
      "loss": 0.0917,
      "step": 12900
    },
    {
      "epoch": 0.30992909923116047,
      "grad_norm": 0.04667601361870766,
      "learning_rate": 0.00017934407135278304,
      "loss": 0.094,
      "step": 12950
    },
    {
      "epoch": 0.3111257366799294,
      "grad_norm": 0.04746098443865776,
      "learning_rate": 0.00017926429409089822,
      "loss": 0.0916,
      "step": 13000
    },
    {
      "epoch": 0.31232237412869834,
      "grad_norm": 0.04282239452004433,
      "learning_rate": 0.0001791845168290134,
      "loss": 0.0954,
      "step": 13050
    },
    {
      "epoch": 0.3135190115774673,
      "grad_norm": 0.04301636666059494,
      "learning_rate": 0.0001791047395671286,
      "loss": 0.091,
      "step": 13100
    },
    {
      "epoch": 0.3147156490262363,
      "grad_norm": 0.08034932613372803,
      "learning_rate": 0.00017902496230524378,
      "loss": 0.0876,
      "step": 13150
    },
    {
      "epoch": 0.31591228647500524,
      "grad_norm": 0.05368485301733017,
      "learning_rate": 0.00017894518504335896,
      "loss": 0.0899,
      "step": 13200
    },
    {
      "epoch": 0.3171089239237742,
      "grad_norm": 0.04773302748799324,
      "learning_rate": 0.00017886540778147414,
      "loss": 0.0917,
      "step": 13250
    },
    {
      "epoch": 0.3183055613725432,
      "grad_norm": 0.055003855377435684,
      "learning_rate": 0.00017878563051958933,
      "loss": 0.0876,
      "step": 13300
    },
    {
      "epoch": 0.3195021988213121,
      "grad_norm": 0.058631181716918945,
      "learning_rate": 0.0001787058532577045,
      "loss": 0.0918,
      "step": 13350
    },
    {
      "epoch": 0.32069883627008106,
      "grad_norm": 0.06473168730735779,
      "learning_rate": 0.0001786260759958197,
      "loss": 0.0859,
      "step": 13400
    },
    {
      "epoch": 0.32189547371885,
      "grad_norm": 0.04965010657906532,
      "learning_rate": 0.00017854629873393488,
      "loss": 0.0849,
      "step": 13450
    },
    {
      "epoch": 0.323092111167619,
      "grad_norm": 0.05629485100507736,
      "learning_rate": 0.00017846652147205004,
      "loss": 0.0944,
      "step": 13500
    },
    {
      "epoch": 0.32428874861638796,
      "grad_norm": 0.04130987823009491,
      "learning_rate": 0.00017838674421016522,
      "loss": 0.0894,
      "step": 13550
    },
    {
      "epoch": 0.3254853860651569,
      "grad_norm": 0.03591618314385414,
      "learning_rate": 0.0001783069669482804,
      "loss": 0.0909,
      "step": 13600
    },
    {
      "epoch": 0.3266820235139259,
      "grad_norm": 0.04703453928232193,
      "learning_rate": 0.0001782271896863956,
      "loss": 0.0931,
      "step": 13650
    },
    {
      "epoch": 0.3278786609626948,
      "grad_norm": 0.05081550031900406,
      "learning_rate": 0.00017814741242451078,
      "loss": 0.0926,
      "step": 13700
    },
    {
      "epoch": 0.32907529841146377,
      "grad_norm": 0.03434576839208603,
      "learning_rate": 0.00017806763516262596,
      "loss": 0.0879,
      "step": 13750
    },
    {
      "epoch": 0.33027193586023273,
      "grad_norm": 0.04349825903773308,
      "learning_rate": 0.00017798785790074112,
      "loss": 0.0835,
      "step": 13800
    },
    {
      "epoch": 0.3314685733090017,
      "grad_norm": 0.05240995064377785,
      "learning_rate": 0.0001779080806388563,
      "loss": 0.0904,
      "step": 13850
    },
    {
      "epoch": 0.33266521075777067,
      "grad_norm": 0.047584328800439835,
      "learning_rate": 0.00017782830337697149,
      "loss": 0.0869,
      "step": 13900
    },
    {
      "epoch": 0.33386184820653964,
      "grad_norm": 0.044033266603946686,
      "learning_rate": 0.00017774852611508667,
      "loss": 0.096,
      "step": 13950
    },
    {
      "epoch": 0.3350584856553086,
      "grad_norm": 0.05377620458602905,
      "learning_rate": 0.00017766874885320185,
      "loss": 0.089,
      "step": 14000
    },
    {
      "epoch": 0.33625512310407757,
      "grad_norm": 0.042843252420425415,
      "learning_rate": 0.00017758897159131704,
      "loss": 0.0875,
      "step": 14050
    },
    {
      "epoch": 0.3374517605528465,
      "grad_norm": 0.04490843415260315,
      "learning_rate": 0.00017750919432943222,
      "loss": 0.0861,
      "step": 14100
    },
    {
      "epoch": 0.33864839800161545,
      "grad_norm": 0.055787354707717896,
      "learning_rate": 0.0001774294170675474,
      "loss": 0.0893,
      "step": 14150
    },
    {
      "epoch": 0.3398450354503844,
      "grad_norm": 0.05093558132648468,
      "learning_rate": 0.0001773496398056626,
      "loss": 0.0906,
      "step": 14200
    },
    {
      "epoch": 0.3410416728991534,
      "grad_norm": 0.04796161875128746,
      "learning_rate": 0.00017726986254377778,
      "loss": 0.0944,
      "step": 14250
    },
    {
      "epoch": 0.34223831034792235,
      "grad_norm": 0.04538821056485176,
      "learning_rate": 0.00017719008528189296,
      "loss": 0.0924,
      "step": 14300
    },
    {
      "epoch": 0.3434349477966913,
      "grad_norm": 0.03976333886384964,
      "learning_rate": 0.00017711030802000814,
      "loss": 0.0834,
      "step": 14350
    },
    {
      "epoch": 0.3446315852454603,
      "grad_norm": 0.05096597597002983,
      "learning_rate": 0.00017703053075812333,
      "loss": 0.09,
      "step": 14400
    },
    {
      "epoch": 0.3458282226942292,
      "grad_norm": 0.031275153160095215,
      "learning_rate": 0.0001769507534962385,
      "loss": 0.0889,
      "step": 14450
    },
    {
      "epoch": 0.34702486014299816,
      "grad_norm": 0.05642695352435112,
      "learning_rate": 0.0001768709762343537,
      "loss": 0.0876,
      "step": 14500
    },
    {
      "epoch": 0.3482214975917671,
      "grad_norm": 0.06066841632127762,
      "learning_rate": 0.00017679119897246888,
      "loss": 0.0886,
      "step": 14550
    },
    {
      "epoch": 0.3494181350405361,
      "grad_norm": 0.04921794682741165,
      "learning_rate": 0.00017671142171058407,
      "loss": 0.0911,
      "step": 14600
    },
    {
      "epoch": 0.35061477248930506,
      "grad_norm": 0.05758606269955635,
      "learning_rate": 0.00017663164444869925,
      "loss": 0.0908,
      "step": 14650
    },
    {
      "epoch": 0.351811409938074,
      "grad_norm": 0.049623556435108185,
      "learning_rate": 0.00017655186718681443,
      "loss": 0.0903,
      "step": 14700
    },
    {
      "epoch": 0.353008047386843,
      "grad_norm": 0.04800570383667946,
      "learning_rate": 0.00017647208992492962,
      "loss": 0.0884,
      "step": 14750
    },
    {
      "epoch": 0.3542046848356119,
      "grad_norm": 0.07236191630363464,
      "learning_rate": 0.0001763923126630448,
      "loss": 0.0852,
      "step": 14800
    },
    {
      "epoch": 0.35540132228438087,
      "grad_norm": 0.04057880491018295,
      "learning_rate": 0.00017631253540115999,
      "loss": 0.0922,
      "step": 14850
    },
    {
      "epoch": 0.35659795973314984,
      "grad_norm": 0.04691803455352783,
      "learning_rate": 0.00017623275813927514,
      "loss": 0.0934,
      "step": 14900
    },
    {
      "epoch": 0.3577945971819188,
      "grad_norm": 0.050939593464136124,
      "learning_rate": 0.00017615298087739033,
      "loss": 0.0911,
      "step": 14950
    },
    {
      "epoch": 0.35899123463068777,
      "grad_norm": 0.060423843562603,
      "learning_rate": 0.0001760732036155055,
      "loss": 0.0913,
      "step": 15000
    },
    {
      "epoch": 0.36018787207945674,
      "grad_norm": 0.06044003739953041,
      "learning_rate": 0.0001759934263536207,
      "loss": 0.0881,
      "step": 15050
    },
    {
      "epoch": 0.3613845095282257,
      "grad_norm": 0.037175536155700684,
      "learning_rate": 0.00017591364909173588,
      "loss": 0.09,
      "step": 15100
    },
    {
      "epoch": 0.3625811469769947,
      "grad_norm": 0.048594843596220016,
      "learning_rate": 0.00017583387182985106,
      "loss": 0.0932,
      "step": 15150
    },
    {
      "epoch": 0.3637777844257636,
      "grad_norm": 0.04222745820879936,
      "learning_rate": 0.00017575409456796625,
      "loss": 0.0876,
      "step": 15200
    },
    {
      "epoch": 0.36497442187453255,
      "grad_norm": 0.06877152621746063,
      "learning_rate": 0.00017567431730608143,
      "loss": 0.0853,
      "step": 15250
    },
    {
      "epoch": 0.3661710593233015,
      "grad_norm": 0.05836711451411247,
      "learning_rate": 0.00017559454004419662,
      "loss": 0.0866,
      "step": 15300
    },
    {
      "epoch": 0.3673676967720705,
      "grad_norm": 0.06156354025006294,
      "learning_rate": 0.0001755147627823118,
      "loss": 0.0923,
      "step": 15350
    },
    {
      "epoch": 0.36856433422083945,
      "grad_norm": 0.03211267665028572,
      "learning_rate": 0.00017543498552042699,
      "loss": 0.0924,
      "step": 15400
    },
    {
      "epoch": 0.3697609716696084,
      "grad_norm": 0.05177624523639679,
      "learning_rate": 0.00017535520825854217,
      "loss": 0.0897,
      "step": 15450
    },
    {
      "epoch": 0.3709576091183774,
      "grad_norm": 0.04874955117702484,
      "learning_rate": 0.00017527543099665733,
      "loss": 0.0937,
      "step": 15500
    },
    {
      "epoch": 0.3721542465671463,
      "grad_norm": 0.054056670516729355,
      "learning_rate": 0.0001751956537347725,
      "loss": 0.0897,
      "step": 15550
    },
    {
      "epoch": 0.37335088401591526,
      "grad_norm": 0.06029222905635834,
      "learning_rate": 0.0001751158764728877,
      "loss": 0.0868,
      "step": 15600
    },
    {
      "epoch": 0.37454752146468423,
      "grad_norm": 0.04308639094233513,
      "learning_rate": 0.00017503609921100288,
      "loss": 0.0899,
      "step": 15650
    },
    {
      "epoch": 0.3757441589134532,
      "grad_norm": 0.056848105043172836,
      "learning_rate": 0.00017495632194911806,
      "loss": 0.0934,
      "step": 15700
    },
    {
      "epoch": 0.37694079636222216,
      "grad_norm": 0.0724954903125763,
      "learning_rate": 0.00017487654468723325,
      "loss": 0.0846,
      "step": 15750
    },
    {
      "epoch": 0.37813743381099113,
      "grad_norm": 0.04949840530753136,
      "learning_rate": 0.00017479676742534843,
      "loss": 0.0901,
      "step": 15800
    },
    {
      "epoch": 0.3793340712597601,
      "grad_norm": 0.057237837463617325,
      "learning_rate": 0.00017471699016346362,
      "loss": 0.0877,
      "step": 15850
    },
    {
      "epoch": 0.380530708708529,
      "grad_norm": 0.05487517639994621,
      "learning_rate": 0.0001746372129015788,
      "loss": 0.0876,
      "step": 15900
    },
    {
      "epoch": 0.381727346157298,
      "grad_norm": 0.05532195419073105,
      "learning_rate": 0.00017455743563969399,
      "loss": 0.0919,
      "step": 15950
    },
    {
      "epoch": 0.38292398360606694,
      "grad_norm": 0.05000677704811096,
      "learning_rate": 0.00017447765837780917,
      "loss": 0.0887,
      "step": 16000
    },
    {
      "epoch": 0.3841206210548359,
      "grad_norm": 0.06362579017877579,
      "learning_rate": 0.00017439788111592435,
      "loss": 0.0903,
      "step": 16050
    },
    {
      "epoch": 0.3853172585036049,
      "grad_norm": 0.0482526496052742,
      "learning_rate": 0.00017431810385403954,
      "loss": 0.0872,
      "step": 16100
    },
    {
      "epoch": 0.38651389595237384,
      "grad_norm": 0.05030273273587227,
      "learning_rate": 0.00017423832659215472,
      "loss": 0.0843,
      "step": 16150
    },
    {
      "epoch": 0.3877105334011428,
      "grad_norm": 0.0677897036075592,
      "learning_rate": 0.0001741585493302699,
      "loss": 0.086,
      "step": 16200
    },
    {
      "epoch": 0.3889071708499117,
      "grad_norm": 0.054784856736660004,
      "learning_rate": 0.00017408036761362277,
      "loss": 0.0904,
      "step": 16250
    },
    {
      "epoch": 0.3901038082986807,
      "grad_norm": 0.04263385757803917,
      "learning_rate": 0.00017400059035173795,
      "loss": 0.0861,
      "step": 16300
    },
    {
      "epoch": 0.39130044574744965,
      "grad_norm": 0.05313282087445259,
      "learning_rate": 0.00017392081308985314,
      "loss": 0.0865,
      "step": 16350
    },
    {
      "epoch": 0.3924970831962186,
      "grad_norm": 0.056978244334459305,
      "learning_rate": 0.00017384103582796832,
      "loss": 0.089,
      "step": 16400
    },
    {
      "epoch": 0.3936937206449876,
      "grad_norm": 0.044471047818660736,
      "learning_rate": 0.0001737612585660835,
      "loss": 0.0895,
      "step": 16450
    },
    {
      "epoch": 0.39489035809375655,
      "grad_norm": 0.05862932279706001,
      "learning_rate": 0.0001736814813041987,
      "loss": 0.0909,
      "step": 16500
    },
    {
      "epoch": 0.3960869955425255,
      "grad_norm": 0.04523294419050217,
      "learning_rate": 0.00017360170404231385,
      "loss": 0.0909,
      "step": 16550
    },
    {
      "epoch": 0.3972836329912945,
      "grad_norm": 0.0401102639734745,
      "learning_rate": 0.00017352192678042903,
      "loss": 0.0948,
      "step": 16600
    },
    {
      "epoch": 0.3984802704400634,
      "grad_norm": 0.04764615371823311,
      "learning_rate": 0.00017344214951854422,
      "loss": 0.0854,
      "step": 16650
    },
    {
      "epoch": 0.39967690788883237,
      "grad_norm": 0.03503981605172157,
      "learning_rate": 0.0001733623722566594,
      "loss": 0.0844,
      "step": 16700
    },
    {
      "epoch": 0.40087354533760133,
      "grad_norm": 0.06901577115058899,
      "learning_rate": 0.00017328259499477459,
      "loss": 0.0912,
      "step": 16750
    },
    {
      "epoch": 0.4020701827863703,
      "grad_norm": 0.03938186168670654,
      "learning_rate": 0.00017320281773288977,
      "loss": 0.0899,
      "step": 16800
    },
    {
      "epoch": 0.40326682023513927,
      "grad_norm": 0.05568636953830719,
      "learning_rate": 0.00017312304047100495,
      "loss": 0.0867,
      "step": 16850
    },
    {
      "epoch": 0.40446345768390823,
      "grad_norm": 0.05497385561466217,
      "learning_rate": 0.00017304326320912014,
      "loss": 0.0877,
      "step": 16900
    },
    {
      "epoch": 0.4056600951326772,
      "grad_norm": 0.037978917360305786,
      "learning_rate": 0.00017296348594723532,
      "loss": 0.0894,
      "step": 16950
    },
    {
      "epoch": 0.4068567325814461,
      "grad_norm": 0.04124865308403969,
      "learning_rate": 0.0001728837086853505,
      "loss": 0.0862,
      "step": 17000
    },
    {
      "epoch": 0.4080533700302151,
      "grad_norm": 0.05337603762745857,
      "learning_rate": 0.0001728039314234657,
      "loss": 0.0937,
      "step": 17050
    },
    {
      "epoch": 0.40925000747898405,
      "grad_norm": 0.04839381203055382,
      "learning_rate": 0.00017272415416158088,
      "loss": 0.0939,
      "step": 17100
    },
    {
      "epoch": 0.410446644927753,
      "grad_norm": 0.051264531910419464,
      "learning_rate": 0.00017264437689969606,
      "loss": 0.0906,
      "step": 17150
    },
    {
      "epoch": 0.411643282376522,
      "grad_norm": 0.04473068565130234,
      "learning_rate": 0.00017256459963781124,
      "loss": 0.091,
      "step": 17200
    },
    {
      "epoch": 0.41283991982529095,
      "grad_norm": 0.06048842519521713,
      "learning_rate": 0.00017248482237592643,
      "loss": 0.088,
      "step": 17250
    },
    {
      "epoch": 0.4140365572740599,
      "grad_norm": 0.05686969682574272,
      "learning_rate": 0.0001724050451140416,
      "loss": 0.0907,
      "step": 17300
    },
    {
      "epoch": 0.4152331947228288,
      "grad_norm": 0.07275111228227615,
      "learning_rate": 0.0001723252678521568,
      "loss": 0.0888,
      "step": 17350
    },
    {
      "epoch": 0.4164298321715978,
      "grad_norm": 0.0483916737139225,
      "learning_rate": 0.00017224549059027198,
      "loss": 0.088,
      "step": 17400
    },
    {
      "epoch": 0.41762646962036676,
      "grad_norm": 0.05791433900594711,
      "learning_rate": 0.00017216571332838717,
      "loss": 0.0857,
      "step": 17450
    },
    {
      "epoch": 0.4188231070691357,
      "grad_norm": 0.04767308384180069,
      "learning_rate": 0.00017208593606650235,
      "loss": 0.0819,
      "step": 17500
    },
    {
      "epoch": 0.4200197445179047,
      "grad_norm": 0.07273595780134201,
      "learning_rate": 0.00017200615880461753,
      "loss": 0.0921,
      "step": 17550
    },
    {
      "epoch": 0.42121638196667366,
      "grad_norm": 0.045373428612947464,
      "learning_rate": 0.00017192638154273272,
      "loss": 0.0897,
      "step": 17600
    },
    {
      "epoch": 0.4224130194154426,
      "grad_norm": 0.04501345381140709,
      "learning_rate": 0.0001718466042808479,
      "loss": 0.0891,
      "step": 17650
    },
    {
      "epoch": 0.4236096568642116,
      "grad_norm": 0.055696528404951096,
      "learning_rate": 0.00017176682701896306,
      "loss": 0.0891,
      "step": 17700
    },
    {
      "epoch": 0.4248062943129805,
      "grad_norm": 0.06412786990404129,
      "learning_rate": 0.00017168704975707824,
      "loss": 0.0898,
      "step": 17750
    },
    {
      "epoch": 0.42600293176174947,
      "grad_norm": 0.05028313398361206,
      "learning_rate": 0.00017160727249519343,
      "loss": 0.084,
      "step": 17800
    },
    {
      "epoch": 0.42719956921051844,
      "grad_norm": 0.04171290993690491,
      "learning_rate": 0.0001715274952333086,
      "loss": 0.0931,
      "step": 17850
    },
    {
      "epoch": 0.4283962066592874,
      "grad_norm": 0.0388229563832283,
      "learning_rate": 0.00017144771797142377,
      "loss": 0.0887,
      "step": 17900
    },
    {
      "epoch": 0.42959284410805637,
      "grad_norm": 0.06944863498210907,
      "learning_rate": 0.00017136794070953895,
      "loss": 0.089,
      "step": 17950
    },
    {
      "epoch": 0.43078948155682534,
      "grad_norm": 0.04637432098388672,
      "learning_rate": 0.00017128816344765414,
      "loss": 0.0867,
      "step": 18000
    },
    {
      "epoch": 0.4319861190055943,
      "grad_norm": 0.04893394559621811,
      "learning_rate": 0.00017120838618576932,
      "loss": 0.0884,
      "step": 18050
    },
    {
      "epoch": 0.4331827564543632,
      "grad_norm": 0.04630941152572632,
      "learning_rate": 0.0001711286089238845,
      "loss": 0.0905,
      "step": 18100
    },
    {
      "epoch": 0.4343793939031322,
      "grad_norm": 0.054486922919750214,
      "learning_rate": 0.0001710488316619997,
      "loss": 0.0863,
      "step": 18150
    },
    {
      "epoch": 0.43557603135190115,
      "grad_norm": 0.045714810490608215,
      "learning_rate": 0.00017096905440011487,
      "loss": 0.0855,
      "step": 18200
    },
    {
      "epoch": 0.4367726688006701,
      "grad_norm": 0.05282525718212128,
      "learning_rate": 0.00017088927713823006,
      "loss": 0.0892,
      "step": 18250
    },
    {
      "epoch": 0.4379693062494391,
      "grad_norm": 0.07104474306106567,
      "learning_rate": 0.00017080949987634524,
      "loss": 0.0885,
      "step": 18300
    },
    {
      "epoch": 0.43916594369820805,
      "grad_norm": 0.06204846873879433,
      "learning_rate": 0.00017072972261446043,
      "loss": 0.0871,
      "step": 18350
    },
    {
      "epoch": 0.440362581146977,
      "grad_norm": 0.063356414437294,
      "learning_rate": 0.0001706499453525756,
      "loss": 0.0901,
      "step": 18400
    },
    {
      "epoch": 0.44155921859574593,
      "grad_norm": 0.04169163107872009,
      "learning_rate": 0.0001705701680906908,
      "loss": 0.0844,
      "step": 18450
    },
    {
      "epoch": 0.4427558560445149,
      "grad_norm": 0.06394816935062408,
      "learning_rate": 0.00017049039082880598,
      "loss": 0.0947,
      "step": 18500
    },
    {
      "epoch": 0.44395249349328386,
      "grad_norm": 0.05890699848532677,
      "learning_rate": 0.00017041061356692116,
      "loss": 0.085,
      "step": 18550
    },
    {
      "epoch": 0.44514913094205283,
      "grad_norm": 0.05124414339661598,
      "learning_rate": 0.00017033083630503635,
      "loss": 0.0843,
      "step": 18600
    },
    {
      "epoch": 0.4463457683908218,
      "grad_norm": 0.05894966423511505,
      "learning_rate": 0.00017025105904315153,
      "loss": 0.092,
      "step": 18650
    },
    {
      "epoch": 0.44754240583959076,
      "grad_norm": 0.0545957051217556,
      "learning_rate": 0.00017017128178126672,
      "loss": 0.0848,
      "step": 18700
    },
    {
      "epoch": 0.44873904328835973,
      "grad_norm": 0.053540218621492386,
      "learning_rate": 0.0001700915045193819,
      "loss": 0.09,
      "step": 18750
    },
    {
      "epoch": 0.4499356807371287,
      "grad_norm": 0.04323490336537361,
      "learning_rate": 0.00017001172725749709,
      "loss": 0.0864,
      "step": 18800
    },
    {
      "epoch": 0.4511323181858976,
      "grad_norm": 0.05079898238182068,
      "learning_rate": 0.00016993194999561227,
      "loss": 0.0835,
      "step": 18850
    },
    {
      "epoch": 0.4523289556346666,
      "grad_norm": 0.05940146744251251,
      "learning_rate": 0.00016985376827896513,
      "loss": 0.0897,
      "step": 18900
    },
    {
      "epoch": 0.45352559308343554,
      "grad_norm": 0.052847109735012054,
      "learning_rate": 0.00016977399101708032,
      "loss": 0.0881,
      "step": 18950
    },
    {
      "epoch": 0.4547222305322045,
      "grad_norm": 0.05639781430363655,
      "learning_rate": 0.0001696942137551955,
      "loss": 0.0896,
      "step": 19000
    },
    {
      "epoch": 0.4559188679809735,
      "grad_norm": 0.045138586312532425,
      "learning_rate": 0.00016961443649331069,
      "loss": 0.0892,
      "step": 19050
    },
    {
      "epoch": 0.45711550542974244,
      "grad_norm": 0.0629303827881813,
      "learning_rate": 0.00016953465923142587,
      "loss": 0.0889,
      "step": 19100
    },
    {
      "epoch": 0.4583121428785114,
      "grad_norm": 0.06618392467498779,
      "learning_rate": 0.00016945488196954105,
      "loss": 0.0875,
      "step": 19150
    },
    {
      "epoch": 0.4595087803272803,
      "grad_norm": 0.06572887301445007,
      "learning_rate": 0.00016937510470765624,
      "loss": 0.0901,
      "step": 19200
    },
    {
      "epoch": 0.4607054177760493,
      "grad_norm": 0.05504794791340828,
      "learning_rate": 0.00016929532744577142,
      "loss": 0.0938,
      "step": 19250
    },
    {
      "epoch": 0.46190205522481825,
      "grad_norm": 0.06767629832029343,
      "learning_rate": 0.0001692155501838866,
      "loss": 0.0885,
      "step": 19300
    },
    {
      "epoch": 0.4630986926735872,
      "grad_norm": 0.05799952149391174,
      "learning_rate": 0.0001691357729220018,
      "loss": 0.0804,
      "step": 19350
    },
    {
      "epoch": 0.4642953301223562,
      "grad_norm": 0.06346601247787476,
      "learning_rate": 0.00016905599566011695,
      "loss": 0.0877,
      "step": 19400
    },
    {
      "epoch": 0.46549196757112515,
      "grad_norm": 0.07962094247341156,
      "learning_rate": 0.00016897621839823213,
      "loss": 0.0873,
      "step": 19450
    },
    {
      "epoch": 0.4666886050198941,
      "grad_norm": 0.059542663395404816,
      "learning_rate": 0.00016889644113634732,
      "loss": 0.0878,
      "step": 19500
    },
    {
      "epoch": 0.46788524246866303,
      "grad_norm": 0.05645611137151718,
      "learning_rate": 0.0001688166638744625,
      "loss": 0.0892,
      "step": 19550
    },
    {
      "epoch": 0.469081879917432,
      "grad_norm": 0.057318296283483505,
      "learning_rate": 0.00016873688661257769,
      "loss": 0.0973,
      "step": 19600
    },
    {
      "epoch": 0.47027851736620097,
      "grad_norm": 0.060118742287158966,
      "learning_rate": 0.00016865710935069287,
      "loss": 0.09,
      "step": 19650
    },
    {
      "epoch": 0.47147515481496993,
      "grad_norm": 0.07066245377063751,
      "learning_rate": 0.00016857733208880805,
      "loss": 0.0848,
      "step": 19700
    },
    {
      "epoch": 0.4726717922637389,
      "grad_norm": 0.05282337963581085,
      "learning_rate": 0.00016849755482692324,
      "loss": 0.0887,
      "step": 19750
    },
    {
      "epoch": 0.47386842971250787,
      "grad_norm": 0.06880160421133041,
      "learning_rate": 0.00016841777756503842,
      "loss": 0.088,
      "step": 19800
    },
    {
      "epoch": 0.47506506716127683,
      "grad_norm": 0.06301864236593246,
      "learning_rate": 0.0001683380003031536,
      "loss": 0.0899,
      "step": 19850
    },
    {
      "epoch": 0.47626170461004574,
      "grad_norm": 0.038324348628520966,
      "learning_rate": 0.0001682582230412688,
      "loss": 0.0848,
      "step": 19900
    },
    {
      "epoch": 0.4774583420588147,
      "grad_norm": 0.05561724677681923,
      "learning_rate": 0.00016817844577938398,
      "loss": 0.0876,
      "step": 19950
    },
    {
      "epoch": 0.4786549795075837,
      "grad_norm": 0.05841447785496712,
      "learning_rate": 0.00016809866851749916,
      "loss": 0.0894,
      "step": 20000
    },
    {
      "epoch": 0.47985161695635264,
      "grad_norm": 0.05768353492021561,
      "learning_rate": 0.00016801889125561434,
      "loss": 0.0859,
      "step": 20050
    },
    {
      "epoch": 0.4810482544051216,
      "grad_norm": 0.041741322726011276,
      "learning_rate": 0.00016793911399372953,
      "loss": 0.0891,
      "step": 20100
    },
    {
      "epoch": 0.4822448918538906,
      "grad_norm": 0.04526752606034279,
      "learning_rate": 0.0001678593367318447,
      "loss": 0.0858,
      "step": 20150
    },
    {
      "epoch": 0.48344152930265955,
      "grad_norm": 0.06440377980470657,
      "learning_rate": 0.0001677795594699599,
      "loss": 0.0883,
      "step": 20200
    },
    {
      "epoch": 0.4846381667514285,
      "grad_norm": 0.04963178560137749,
      "learning_rate": 0.00016769978220807508,
      "loss": 0.0866,
      "step": 20250
    },
    {
      "epoch": 0.4858348042001974,
      "grad_norm": 0.06768721342086792,
      "learning_rate": 0.00016762000494619024,
      "loss": 0.0846,
      "step": 20300
    },
    {
      "epoch": 0.4870314416489664,
      "grad_norm": 0.04935808479785919,
      "learning_rate": 0.00016754022768430542,
      "loss": 0.0927,
      "step": 20350
    },
    {
      "epoch": 0.48822807909773536,
      "grad_norm": 0.046769436448812485,
      "learning_rate": 0.0001674604504224206,
      "loss": 0.0857,
      "step": 20400
    },
    {
      "epoch": 0.4894247165465043,
      "grad_norm": 0.04828639328479767,
      "learning_rate": 0.0001673806731605358,
      "loss": 0.0881,
      "step": 20450
    },
    {
      "epoch": 0.4906213539952733,
      "grad_norm": 0.075270876288414,
      "learning_rate": 0.00016730089589865097,
      "loss": 0.0895,
      "step": 20500
    },
    {
      "epoch": 0.49181799144404226,
      "grad_norm": 0.04664129763841629,
      "learning_rate": 0.00016722111863676616,
      "loss": 0.0876,
      "step": 20550
    },
    {
      "epoch": 0.4930146288928112,
      "grad_norm": 0.062389954924583435,
      "learning_rate": 0.00016714134137488134,
      "loss": 0.0895,
      "step": 20600
    },
    {
      "epoch": 0.49421126634158014,
      "grad_norm": 0.0569019690155983,
      "learning_rate": 0.00016706156411299653,
      "loss": 0.0889,
      "step": 20650
    },
    {
      "epoch": 0.4954079037903491,
      "grad_norm": 0.045382723212242126,
      "learning_rate": 0.0001669817868511117,
      "loss": 0.0804,
      "step": 20700
    },
    {
      "epoch": 0.49660454123911807,
      "grad_norm": 0.05437765270471573,
      "learning_rate": 0.00016690200958922687,
      "loss": 0.0892,
      "step": 20750
    },
    {
      "epoch": 0.49780117868788704,
      "grad_norm": 0.043555378913879395,
      "learning_rate": 0.00016682223232734205,
      "loss": 0.0896,
      "step": 20800
    },
    {
      "epoch": 0.498997816136656,
      "grad_norm": 0.04145096614956856,
      "learning_rate": 0.00016674245506545724,
      "loss": 0.084,
      "step": 20850
    },
    {
      "epoch": 0.5001944535854249,
      "grad_norm": 0.0654924139380455,
      "learning_rate": 0.00016666267780357242,
      "loss": 0.0871,
      "step": 20900
    },
    {
      "epoch": 0.5013910910341939,
      "grad_norm": 0.050158124417066574,
      "learning_rate": 0.0001665829005416876,
      "loss": 0.0866,
      "step": 20950
    },
    {
      "epoch": 0.5025877284829628,
      "grad_norm": 0.04159451276063919,
      "learning_rate": 0.0001665047188250405,
      "loss": 0.0934,
      "step": 21000
    },
    {
      "epoch": 0.5037843659317318,
      "grad_norm": 0.06602421402931213,
      "learning_rate": 0.00016642494156315565,
      "loss": 0.0856,
      "step": 21050
    },
    {
      "epoch": 0.5049810033805008,
      "grad_norm": 0.047393009066581726,
      "learning_rate": 0.00016634516430127084,
      "loss": 0.0906,
      "step": 21100
    },
    {
      "epoch": 0.5061776408292697,
      "grad_norm": 0.06611043214797974,
      "learning_rate": 0.00016626538703938602,
      "loss": 0.0944,
      "step": 21150
    },
    {
      "epoch": 0.5073742782780387,
      "grad_norm": 0.04297725483775139,
      "learning_rate": 0.0001661856097775012,
      "loss": 0.087,
      "step": 21200
    },
    {
      "epoch": 0.5085709157268077,
      "grad_norm": 0.05385155603289604,
      "learning_rate": 0.0001661058325156164,
      "loss": 0.086,
      "step": 21250
    },
    {
      "epoch": 0.5097675531755766,
      "grad_norm": 0.04307173565030098,
      "learning_rate": 0.00016602605525373158,
      "loss": 0.088,
      "step": 21300
    },
    {
      "epoch": 0.5109641906243456,
      "grad_norm": 0.049864962697029114,
      "learning_rate": 0.00016594627799184676,
      "loss": 0.0863,
      "step": 21350
    },
    {
      "epoch": 0.5121608280731146,
      "grad_norm": 0.052018504589796066,
      "learning_rate": 0.00016586650072996194,
      "loss": 0.089,
      "step": 21400
    },
    {
      "epoch": 0.5133574655218835,
      "grad_norm": 0.05209365487098694,
      "learning_rate": 0.00016578672346807713,
      "loss": 0.085,
      "step": 21450
    },
    {
      "epoch": 0.5145541029706525,
      "grad_norm": 0.04752824082970619,
      "learning_rate": 0.0001657069462061923,
      "loss": 0.0891,
      "step": 21500
    },
    {
      "epoch": 0.5157507404194214,
      "grad_norm": 0.05541594699025154,
      "learning_rate": 0.0001656271689443075,
      "loss": 0.0852,
      "step": 21550
    },
    {
      "epoch": 0.5169473778681903,
      "grad_norm": 0.03410904109477997,
      "learning_rate": 0.00016554739168242268,
      "loss": 0.086,
      "step": 21600
    },
    {
      "epoch": 0.5181440153169593,
      "grad_norm": 0.04545362666249275,
      "learning_rate": 0.00016546761442053786,
      "loss": 0.0884,
      "step": 21650
    },
    {
      "epoch": 0.5193406527657283,
      "grad_norm": 0.05137936770915985,
      "learning_rate": 0.00016538783715865305,
      "loss": 0.0921,
      "step": 21700
    },
    {
      "epoch": 0.5205372902144972,
      "grad_norm": 0.045540403574705124,
      "learning_rate": 0.00016530805989676823,
      "loss": 0.0935,
      "step": 21750
    },
    {
      "epoch": 0.5217339276632662,
      "grad_norm": 0.07837194949388504,
      "learning_rate": 0.00016522828263488342,
      "loss": 0.0914,
      "step": 21800
    },
    {
      "epoch": 0.5229305651120352,
      "grad_norm": 0.04085991159081459,
      "learning_rate": 0.0001651485053729986,
      "loss": 0.0838,
      "step": 21850
    },
    {
      "epoch": 0.5241272025608041,
      "grad_norm": 0.047088831663131714,
      "learning_rate": 0.00016506872811111379,
      "loss": 0.0862,
      "step": 21900
    },
    {
      "epoch": 0.5253238400095731,
      "grad_norm": 0.05431528016924858,
      "learning_rate": 0.00016498895084922897,
      "loss": 0.0891,
      "step": 21950
    },
    {
      "epoch": 0.5265204774583421,
      "grad_norm": 0.08545247465372086,
      "learning_rate": 0.00016490917358734415,
      "loss": 0.0817,
      "step": 22000
    },
    {
      "epoch": 0.527717114907111,
      "grad_norm": 0.05476713180541992,
      "learning_rate": 0.00016482939632545934,
      "loss": 0.0853,
      "step": 22050
    },
    {
      "epoch": 0.52891375235588,
      "grad_norm": 0.05344213917851448,
      "learning_rate": 0.00016474961906357452,
      "loss": 0.0933,
      "step": 22100
    },
    {
      "epoch": 0.530110389804649,
      "grad_norm": 0.04728109389543533,
      "learning_rate": 0.0001646698418016897,
      "loss": 0.0869,
      "step": 22150
    },
    {
      "epoch": 0.5313070272534179,
      "grad_norm": 0.06556009501218796,
      "learning_rate": 0.0001645900645398049,
      "loss": 0.0935,
      "step": 22200
    },
    {
      "epoch": 0.5325036647021869,
      "grad_norm": 0.05456060916185379,
      "learning_rate": 0.00016451028727792005,
      "loss": 0.0903,
      "step": 22250
    },
    {
      "epoch": 0.5337003021509558,
      "grad_norm": 0.06349317729473114,
      "learning_rate": 0.00016443051001603523,
      "loss": 0.087,
      "step": 22300
    },
    {
      "epoch": 0.5348969395997247,
      "grad_norm": 0.06802967190742493,
      "learning_rate": 0.00016435073275415042,
      "loss": 0.0835,
      "step": 22350
    },
    {
      "epoch": 0.5360935770484937,
      "grad_norm": 0.06779127568006516,
      "learning_rate": 0.0001642709554922656,
      "loss": 0.088,
      "step": 22400
    },
    {
      "epoch": 0.5372902144972627,
      "grad_norm": 0.06737516075372696,
      "learning_rate": 0.00016419117823038079,
      "loss": 0.0832,
      "step": 22450
    },
    {
      "epoch": 0.5384868519460316,
      "grad_norm": 0.0665733590722084,
      "learning_rate": 0.00016411140096849597,
      "loss": 0.0924,
      "step": 22500
    },
    {
      "epoch": 0.5396834893948006,
      "grad_norm": 0.052185751497745514,
      "learning_rate": 0.00016403162370661115,
      "loss": 0.084,
      "step": 22550
    },
    {
      "epoch": 0.5408801268435696,
      "grad_norm": 0.06952589005231857,
      "learning_rate": 0.00016395184644472634,
      "loss": 0.0857,
      "step": 22600
    },
    {
      "epoch": 0.5420767642923385,
      "grad_norm": 0.052718453109264374,
      "learning_rate": 0.0001638720691828415,
      "loss": 0.0836,
      "step": 22650
    },
    {
      "epoch": 0.5432734017411075,
      "grad_norm": 0.04110296443104744,
      "learning_rate": 0.00016379229192095668,
      "loss": 0.0861,
      "step": 22700
    },
    {
      "epoch": 0.5444700391898765,
      "grad_norm": 0.049448251724243164,
      "learning_rate": 0.00016371251465907186,
      "loss": 0.091,
      "step": 22750
    },
    {
      "epoch": 0.5456666766386454,
      "grad_norm": 0.060199663043022156,
      "learning_rate": 0.00016363273739718705,
      "loss": 0.0882,
      "step": 22800
    },
    {
      "epoch": 0.5468633140874144,
      "grad_norm": 0.054117295891046524,
      "learning_rate": 0.00016355296013530223,
      "loss": 0.0859,
      "step": 22850
    },
    {
      "epoch": 0.5480599515361834,
      "grad_norm": 0.08028198033571243,
      "learning_rate": 0.00016347318287341742,
      "loss": 0.0905,
      "step": 22900
    },
    {
      "epoch": 0.5492565889849523,
      "grad_norm": 0.07381368428468704,
      "learning_rate": 0.0001633934056115326,
      "loss": 0.0927,
      "step": 22950
    },
    {
      "epoch": 0.5504532264337213,
      "grad_norm": 0.04869445785880089,
      "learning_rate": 0.00016331362834964779,
      "loss": 0.0889,
      "step": 23000
    },
    {
      "epoch": 0.5516498638824902,
      "grad_norm": 0.061022013425827026,
      "learning_rate": 0.00016323385108776297,
      "loss": 0.08,
      "step": 23050
    },
    {
      "epoch": 0.5528465013312591,
      "grad_norm": Infinity,
      "learning_rate": 0.00016315407382587815,
      "loss": 0.0869,
      "step": 23100
    },
    {
      "epoch": 0.5540431387800281,
      "grad_norm": 0.048207838088274,
      "learning_rate": 0.00016307589210923104,
      "loss": 0.0893,
      "step": 23150
    },
    {
      "epoch": 0.555239776228797,
      "grad_norm": 0.07165519893169403,
      "learning_rate": 0.00016299611484734623,
      "loss": 0.0898,
      "step": 23200
    },
    {
      "epoch": 0.556436413677566,
      "grad_norm": 0.0575714185833931,
      "learning_rate": 0.0001629163375854614,
      "loss": 0.0883,
      "step": 23250
    },
    {
      "epoch": 0.557633051126335,
      "grad_norm": 0.05796065554022789,
      "learning_rate": 0.0001628365603235766,
      "loss": 0.0875,
      "step": 23300
    },
    {
      "epoch": 0.558829688575104,
      "grad_norm": 0.05797199904918671,
      "learning_rate": 0.00016275678306169178,
      "loss": 0.0857,
      "step": 23350
    },
    {
      "epoch": 0.5600263260238729,
      "grad_norm": 0.05919890105724335,
      "learning_rate": 0.00016267700579980694,
      "loss": 0.0932,
      "step": 23400
    },
    {
      "epoch": 0.5612229634726419,
      "grad_norm": 0.045508768409490585,
      "learning_rate": 0.00016259722853792212,
      "loss": 0.0877,
      "step": 23450
    },
    {
      "epoch": 0.5624196009214109,
      "grad_norm": 0.07243037223815918,
      "learning_rate": 0.0001625174512760373,
      "loss": 0.0908,
      "step": 23500
    },
    {
      "epoch": 0.5636162383701798,
      "grad_norm": 0.07205654680728912,
      "learning_rate": 0.0001624376740141525,
      "loss": 0.0884,
      "step": 23550
    },
    {
      "epoch": 0.5648128758189488,
      "grad_norm": 0.06871656328439713,
      "learning_rate": 0.00016235789675226768,
      "loss": 0.0894,
      "step": 23600
    },
    {
      "epoch": 0.5660095132677178,
      "grad_norm": 0.08627892285585403,
      "learning_rate": 0.00016227811949038286,
      "loss": 0.0897,
      "step": 23650
    },
    {
      "epoch": 0.5672061507164867,
      "grad_norm": 0.07997962087392807,
      "learning_rate": 0.00016219834222849804,
      "loss": 0.0901,
      "step": 23700
    },
    {
      "epoch": 0.5684027881652556,
      "grad_norm": 0.05322009325027466,
      "learning_rate": 0.00016211856496661323,
      "loss": 0.0871,
      "step": 23750
    },
    {
      "epoch": 0.5695994256140245,
      "grad_norm": 0.04070383310317993,
      "learning_rate": 0.0001620387877047284,
      "loss": 0.0838,
      "step": 23800
    },
    {
      "epoch": 0.5707960630627935,
      "grad_norm": 0.04971228167414665,
      "learning_rate": 0.0001619590104428436,
      "loss": 0.0887,
      "step": 23850
    },
    {
      "epoch": 0.5719927005115625,
      "grad_norm": 0.053008127957582474,
      "learning_rate": 0.00016187923318095875,
      "loss": 0.0851,
      "step": 23900
    },
    {
      "epoch": 0.5731893379603314,
      "grad_norm": 0.04151299595832825,
      "learning_rate": 0.00016179945591907394,
      "loss": 0.0835,
      "step": 23950
    },
    {
      "epoch": 0.5743859754091004,
      "grad_norm": 0.055079385638237,
      "learning_rate": 0.00016171967865718912,
      "loss": 0.0853,
      "step": 24000
    },
    {
      "epoch": 0.5755826128578694,
      "grad_norm": 0.06077175587415695,
      "learning_rate": 0.0001616399013953043,
      "loss": 0.0907,
      "step": 24050
    },
    {
      "epoch": 0.5767792503066383,
      "grad_norm": 0.048982299864292145,
      "learning_rate": 0.0001615601241334195,
      "loss": 0.0859,
      "step": 24100
    },
    {
      "epoch": 0.5779758877554073,
      "grad_norm": 0.058236345648765564,
      "learning_rate": 0.00016148034687153468,
      "loss": 0.086,
      "step": 24150
    },
    {
      "epoch": 0.5791725252041763,
      "grad_norm": 0.06056255102157593,
      "learning_rate": 0.00016140056960964986,
      "loss": 0.0964,
      "step": 24200
    },
    {
      "epoch": 0.5803691626529452,
      "grad_norm": 0.05061329901218414,
      "learning_rate": 0.00016132079234776504,
      "loss": 0.0915,
      "step": 24250
    },
    {
      "epoch": 0.5815658001017142,
      "grad_norm": 0.05985471233725548,
      "learning_rate": 0.00016124101508588023,
      "loss": 0.086,
      "step": 24300
    },
    {
      "epoch": 0.5827624375504832,
      "grad_norm": 0.06326617300510406,
      "learning_rate": 0.0001611612378239954,
      "loss": 0.086,
      "step": 24350
    },
    {
      "epoch": 0.5839590749992521,
      "grad_norm": 0.06120011955499649,
      "learning_rate": 0.0001610814605621106,
      "loss": 0.0956,
      "step": 24400
    },
    {
      "epoch": 0.5851557124480211,
      "grad_norm": 0.09703263640403748,
      "learning_rate": 0.00016100168330022578,
      "loss": 0.091,
      "step": 24450
    },
    {
      "epoch": 0.58635234989679,
      "grad_norm": 0.062346458435058594,
      "learning_rate": 0.00016092190603834096,
      "loss": 0.0876,
      "step": 24500
    },
    {
      "epoch": 0.5875489873455589,
      "grad_norm": 0.06623469293117523,
      "learning_rate": 0.00016084212877645615,
      "loss": 0.0846,
      "step": 24550
    },
    {
      "epoch": 0.5887456247943279,
      "grad_norm": 0.05667361244559288,
      "learning_rate": 0.00016076235151457133,
      "loss": 0.0849,
      "step": 24600
    },
    {
      "epoch": 0.5899422622430969,
      "grad_norm": 0.049719177186489105,
      "learning_rate": 0.00016068257425268652,
      "loss": 0.0874,
      "step": 24650
    },
    {
      "epoch": 0.5911388996918658,
      "grad_norm": 0.06647948175668716,
      "learning_rate": 0.0001606027969908017,
      "loss": 0.0826,
      "step": 24700
    },
    {
      "epoch": 0.5923355371406348,
      "grad_norm": 0.06487008929252625,
      "learning_rate": 0.00016052301972891689,
      "loss": 0.0887,
      "step": 24750
    },
    {
      "epoch": 0.5935321745894038,
      "grad_norm": 0.06269065290689468,
      "learning_rate": 0.00016044324246703207,
      "loss": 0.0855,
      "step": 24800
    },
    {
      "epoch": 0.5947288120381727,
      "grad_norm": 0.058919697999954224,
      "learning_rate": 0.00016036346520514725,
      "loss": 0.0913,
      "step": 24850
    },
    {
      "epoch": 0.5959254494869417,
      "grad_norm": 0.060758285224437714,
      "learning_rate": 0.00016028368794326244,
      "loss": 0.0833,
      "step": 24900
    },
    {
      "epoch": 0.5971220869357107,
      "grad_norm": 0.046307943761348724,
      "learning_rate": 0.00016020391068137762,
      "loss": 0.0871,
      "step": 24950
    },
    {
      "epoch": 0.5983187243844796,
      "grad_norm": 0.04640449956059456,
      "learning_rate": 0.0001601241334194928,
      "loss": 0.0889,
      "step": 25000
    },
    {
      "epoch": 0.5995153618332486,
      "grad_norm": 0.051384199410676956,
      "learning_rate": 0.00016004435615760796,
      "loss": 0.0859,
      "step": 25050
    },
    {
      "epoch": 0.6007119992820176,
      "grad_norm": 0.059007953852415085,
      "learning_rate": 0.00015996457889572315,
      "loss": 0.0859,
      "step": 25100
    },
    {
      "epoch": 0.6019086367307865,
      "grad_norm": 0.046169571578502655,
      "learning_rate": 0.00015988480163383833,
      "loss": 0.0901,
      "step": 25150
    },
    {
      "epoch": 0.6031052741795554,
      "grad_norm": 0.06600576639175415,
      "learning_rate": 0.00015980661991719122,
      "loss": 0.0856,
      "step": 25200
    },
    {
      "epoch": 0.6043019116283244,
      "grad_norm": 0.05361463129520416,
      "learning_rate": 0.0001597268426553064,
      "loss": 0.0892,
      "step": 25250
    },
    {
      "epoch": 0.6054985490770933,
      "grad_norm": 0.05066940188407898,
      "learning_rate": 0.0001596470653934216,
      "loss": 0.0866,
      "step": 25300
    },
    {
      "epoch": 0.6066951865258623,
      "grad_norm": 0.05211520940065384,
      "learning_rate": 0.00015956728813153678,
      "loss": 0.0861,
      "step": 25350
    },
    {
      "epoch": 0.6078918239746313,
      "grad_norm": 0.05791906639933586,
      "learning_rate": 0.00015948751086965193,
      "loss": 0.0886,
      "step": 25400
    },
    {
      "epoch": 0.6090884614234002,
      "grad_norm": 0.08136492222547531,
      "learning_rate": 0.00015940773360776712,
      "loss": 0.0891,
      "step": 25450
    },
    {
      "epoch": 0.6102850988721692,
      "grad_norm": 0.04979124665260315,
      "learning_rate": 0.0001593279563458823,
      "loss": 0.0876,
      "step": 25500
    },
    {
      "epoch": 0.6114817363209382,
      "grad_norm": 0.07364274561405182,
      "learning_rate": 0.00015924817908399749,
      "loss": 0.0882,
      "step": 25550
    },
    {
      "epoch": 0.6126783737697071,
      "grad_norm": 0.054740097373723984,
      "learning_rate": 0.00015916840182211267,
      "loss": 0.0895,
      "step": 25600
    },
    {
      "epoch": 0.6138750112184761,
      "grad_norm": 0.05427306890487671,
      "learning_rate": 0.00015908862456022785,
      "loss": 0.0842,
      "step": 25650
    },
    {
      "epoch": 0.6150716486672451,
      "grad_norm": 0.0600825697183609,
      "learning_rate": 0.00015900884729834304,
      "loss": 0.0865,
      "step": 25700
    },
    {
      "epoch": 0.616268286116014,
      "grad_norm": 0.05624736472964287,
      "learning_rate": 0.0001589290700364582,
      "loss": 0.0868,
      "step": 25750
    },
    {
      "epoch": 0.617464923564783,
      "grad_norm": 0.03856761008501053,
      "learning_rate": 0.00015884929277457338,
      "loss": 0.0854,
      "step": 25800
    },
    {
      "epoch": 0.618661561013552,
      "grad_norm": 0.054984427988529205,
      "learning_rate": 0.00015876951551268856,
      "loss": 0.0877,
      "step": 25850
    },
    {
      "epoch": 0.6198581984623209,
      "grad_norm": 0.07327456772327423,
      "learning_rate": 0.00015868973825080375,
      "loss": 0.0864,
      "step": 25900
    },
    {
      "epoch": 0.6210548359110898,
      "grad_norm": 0.07020052522420883,
      "learning_rate": 0.00015860996098891893,
      "loss": 0.0913,
      "step": 25950
    },
    {
      "epoch": 0.6222514733598588,
      "grad_norm": 0.07000944763422012,
      "learning_rate": 0.00015853018372703412,
      "loss": 0.0854,
      "step": 26000
    },
    {
      "epoch": 0.6234481108086277,
      "grad_norm": 0.045458558946847916,
      "learning_rate": 0.0001584504064651493,
      "loss": 0.0946,
      "step": 26050
    },
    {
      "epoch": 0.6246447482573967,
      "grad_norm": 0.06803609430789948,
      "learning_rate": 0.00015837062920326449,
      "loss": 0.09,
      "step": 26100
    },
    {
      "epoch": 0.6258413857061657,
      "grad_norm": 0.06443897634744644,
      "learning_rate": 0.00015829085194137967,
      "loss": 0.0825,
      "step": 26150
    },
    {
      "epoch": 0.6270380231549346,
      "grad_norm": 0.053022272884845734,
      "learning_rate": 0.00015821107467949485,
      "loss": 0.0909,
      "step": 26200
    },
    {
      "epoch": 0.6282346606037036,
      "grad_norm": 0.04416579008102417,
      "learning_rate": 0.00015813129741761004,
      "loss": 0.0824,
      "step": 26250
    },
    {
      "epoch": 0.6294312980524726,
      "grad_norm": 0.05892733857035637,
      "learning_rate": 0.00015805152015572522,
      "loss": 0.0859,
      "step": 26300
    },
    {
      "epoch": 0.6306279355012415,
      "grad_norm": 0.04731964319944382,
      "learning_rate": 0.0001579717428938404,
      "loss": 0.0842,
      "step": 26350
    },
    {
      "epoch": 0.6318245729500105,
      "grad_norm": 0.054841767996549606,
      "learning_rate": 0.0001578919656319556,
      "loss": 0.0925,
      "step": 26400
    },
    {
      "epoch": 0.6330212103987795,
      "grad_norm": 0.07627590745687485,
      "learning_rate": 0.00015781218837007078,
      "loss": 0.0878,
      "step": 26450
    },
    {
      "epoch": 0.6342178478475484,
      "grad_norm": 0.06696882098913193,
      "learning_rate": 0.00015773241110818596,
      "loss": 0.0845,
      "step": 26500
    },
    {
      "epoch": 0.6354144852963174,
      "grad_norm": 0.08076291531324387,
      "learning_rate": 0.00015765263384630114,
      "loss": 0.0809,
      "step": 26550
    },
    {
      "epoch": 0.6366111227450864,
      "grad_norm": 0.05282464623451233,
      "learning_rate": 0.00015757285658441633,
      "loss": 0.085,
      "step": 26600
    },
    {
      "epoch": 0.6378077601938553,
      "grad_norm": 0.07885787636041641,
      "learning_rate": 0.0001574930793225315,
      "loss": 0.0904,
      "step": 26650
    },
    {
      "epoch": 0.6390043976426242,
      "grad_norm": 0.049706656485795975,
      "learning_rate": 0.0001574133020606467,
      "loss": 0.0825,
      "step": 26700
    },
    {
      "epoch": 0.6402010350913931,
      "grad_norm": 0.0606616735458374,
      "learning_rate": 0.00015733352479876185,
      "loss": 0.0813,
      "step": 26750
    },
    {
      "epoch": 0.6413976725401621,
      "grad_norm": 0.07536101341247559,
      "learning_rate": 0.00015725374753687704,
      "loss": 0.0907,
      "step": 26800
    },
    {
      "epoch": 0.6425943099889311,
      "grad_norm": 0.049696266651153564,
      "learning_rate": 0.00015717397027499222,
      "loss": 0.0877,
      "step": 26850
    },
    {
      "epoch": 0.6437909474377,
      "grad_norm": 0.07366631180047989,
      "learning_rate": 0.0001570941930131074,
      "loss": 0.0844,
      "step": 26900
    },
    {
      "epoch": 0.644987584886469,
      "grad_norm": 0.0639554113149643,
      "learning_rate": 0.0001570144157512226,
      "loss": 0.0893,
      "step": 26950
    },
    {
      "epoch": 0.646184222335238,
      "grad_norm": 0.06622844189405441,
      "learning_rate": 0.00015693463848933777,
      "loss": 0.0839,
      "step": 27000
    },
    {
      "epoch": 0.647380859784007,
      "grad_norm": 0.060821160674095154,
      "learning_rate": 0.00015685486122745296,
      "loss": 0.0878,
      "step": 27050
    },
    {
      "epoch": 0.6485774972327759,
      "grad_norm": 0.06179455295205116,
      "learning_rate": 0.00015677508396556814,
      "loss": 0.086,
      "step": 27100
    },
    {
      "epoch": 0.6497741346815449,
      "grad_norm": 0.05931759998202324,
      "learning_rate": 0.00015669530670368333,
      "loss": 0.086,
      "step": 27150
    },
    {
      "epoch": 0.6509707721303138,
      "grad_norm": 0.07651989161968231,
      "learning_rate": 0.0001566155294417985,
      "loss": 0.0849,
      "step": 27200
    },
    {
      "epoch": 0.6521674095790828,
      "grad_norm": 0.0505489818751812,
      "learning_rate": 0.00015653734772515138,
      "loss": 0.0864,
      "step": 27250
    },
    {
      "epoch": 0.6533640470278518,
      "grad_norm": 0.06509199738502502,
      "learning_rate": 0.00015645757046326656,
      "loss": 0.0844,
      "step": 27300
    },
    {
      "epoch": 0.6545606844766207,
      "grad_norm": 0.0462661013007164,
      "learning_rate": 0.00015637779320138174,
      "loss": 0.0856,
      "step": 27350
    },
    {
      "epoch": 0.6557573219253896,
      "grad_norm": 0.05211186036467552,
      "learning_rate": 0.00015629801593949693,
      "loss": 0.0848,
      "step": 27400
    },
    {
      "epoch": 0.6569539593741586,
      "grad_norm": 0.0734313353896141,
      "learning_rate": 0.0001562182386776121,
      "loss": 0.0884,
      "step": 27450
    },
    {
      "epoch": 0.6581505968229275,
      "grad_norm": 0.06173015013337135,
      "learning_rate": 0.0001561384614157273,
      "loss": 0.0802,
      "step": 27500
    },
    {
      "epoch": 0.6593472342716965,
      "grad_norm": 0.056074175983667374,
      "learning_rate": 0.00015605868415384248,
      "loss": 0.0836,
      "step": 27550
    },
    {
      "epoch": 0.6605438717204655,
      "grad_norm": 0.06276959180831909,
      "learning_rate": 0.00015597890689195767,
      "loss": 0.0839,
      "step": 27600
    },
    {
      "epoch": 0.6617405091692344,
      "grad_norm": 0.044231053441762924,
      "learning_rate": 0.00015589912963007285,
      "loss": 0.0817,
      "step": 27650
    },
    {
      "epoch": 0.6629371466180034,
      "grad_norm": 0.06101929396390915,
      "learning_rate": 0.00015581935236818803,
      "loss": 0.0806,
      "step": 27700
    },
    {
      "epoch": 0.6641337840667724,
      "grad_norm": 0.0681748315691948,
      "learning_rate": 0.00015573957510630322,
      "loss": 0.0841,
      "step": 27750
    },
    {
      "epoch": 0.6653304215155413,
      "grad_norm": 0.0707019791007042,
      "learning_rate": 0.0001556597978444184,
      "loss": 0.0874,
      "step": 27800
    },
    {
      "epoch": 0.6665270589643103,
      "grad_norm": 0.05595548823475838,
      "learning_rate": 0.0001555800205825336,
      "loss": 0.0843,
      "step": 27850
    },
    {
      "epoch": 0.6677236964130793,
      "grad_norm": 0.08436290919780731,
      "learning_rate": 0.00015550024332064877,
      "loss": 0.0822,
      "step": 27900
    },
    {
      "epoch": 0.6689203338618482,
      "grad_norm": 0.07303032279014587,
      "learning_rate": 0.00015542046605876396,
      "loss": 0.0898,
      "step": 27950
    },
    {
      "epoch": 0.6701169713106172,
      "grad_norm": 0.044315170496702194,
      "learning_rate": 0.00015534068879687914,
      "loss": 0.0872,
      "step": 28000
    },
    {
      "epoch": 0.6713136087593862,
      "grad_norm": 0.06017255410552025,
      "learning_rate": 0.00015526091153499432,
      "loss": 0.0868,
      "step": 28050
    },
    {
      "epoch": 0.6725102462081551,
      "grad_norm": 0.05482799932360649,
      "learning_rate": 0.0001551811342731095,
      "loss": 0.0897,
      "step": 28100
    },
    {
      "epoch": 0.673706883656924,
      "grad_norm": 0.07492077350616455,
      "learning_rate": 0.00015510135701122466,
      "loss": 0.0885,
      "step": 28150
    },
    {
      "epoch": 0.674903521105693,
      "grad_norm": 0.047730688005685806,
      "learning_rate": 0.00015502157974933985,
      "loss": 0.0856,
      "step": 28200
    },
    {
      "epoch": 0.6761001585544619,
      "grad_norm": 0.08324303478002548,
      "learning_rate": 0.00015494180248745503,
      "loss": 0.0871,
      "step": 28250
    },
    {
      "epoch": 0.6772967960032309,
      "grad_norm": 0.07343336939811707,
      "learning_rate": 0.00015486202522557022,
      "loss": 0.0843,
      "step": 28300
    },
    {
      "epoch": 0.6784934334519999,
      "grad_norm": 0.044611066579818726,
      "learning_rate": 0.0001547822479636854,
      "loss": 0.0858,
      "step": 28350
    },
    {
      "epoch": 0.6796900709007688,
      "grad_norm": 0.05632977932691574,
      "learning_rate": 0.00015470247070180059,
      "loss": 0.081,
      "step": 28400
    },
    {
      "epoch": 0.6808867083495378,
      "grad_norm": 0.06389917433261871,
      "learning_rate": 0.00015462269343991574,
      "loss": 0.0878,
      "step": 28450
    },
    {
      "epoch": 0.6820833457983068,
      "grad_norm": 0.068302221596241,
      "learning_rate": 0.00015454291617803093,
      "loss": 0.0904,
      "step": 28500
    },
    {
      "epoch": 0.6832799832470757,
      "grad_norm": 0.05716732516884804,
      "learning_rate": 0.0001544631389161461,
      "loss": 0.095,
      "step": 28550
    },
    {
      "epoch": 0.6844766206958447,
      "grad_norm": 0.056967660784721375,
      "learning_rate": 0.0001543833616542613,
      "loss": 0.0865,
      "step": 28600
    },
    {
      "epoch": 0.6856732581446137,
      "grad_norm": 0.07691506296396255,
      "learning_rate": 0.00015430358439237648,
      "loss": 0.0842,
      "step": 28650
    },
    {
      "epoch": 0.6868698955933826,
      "grad_norm": 0.05760236084461212,
      "learning_rate": 0.00015422380713049166,
      "loss": 0.0807,
      "step": 28700
    },
    {
      "epoch": 0.6880665330421516,
      "grad_norm": 0.08997321873903275,
      "learning_rate": 0.00015414402986860685,
      "loss": 0.0834,
      "step": 28750
    },
    {
      "epoch": 0.6892631704909206,
      "grad_norm": 0.0659007877111435,
      "learning_rate": 0.00015406425260672203,
      "loss": 0.0854,
      "step": 28800
    },
    {
      "epoch": 0.6904598079396894,
      "grad_norm": 0.0454479455947876,
      "learning_rate": 0.00015398447534483722,
      "loss": 0.0848,
      "step": 28850
    },
    {
      "epoch": 0.6916564453884584,
      "grad_norm": 0.06988286972045898,
      "learning_rate": 0.0001539046980829524,
      "loss": 0.0829,
      "step": 28900
    },
    {
      "epoch": 0.6928530828372274,
      "grad_norm": 0.05641307681798935,
      "learning_rate": 0.00015382492082106759,
      "loss": 0.0864,
      "step": 28950
    },
    {
      "epoch": 0.6940497202859963,
      "grad_norm": 0.058603379875421524,
      "learning_rate": 0.00015374514355918277,
      "loss": 0.0874,
      "step": 29000
    },
    {
      "epoch": 0.6952463577347653,
      "grad_norm": 0.07177703827619553,
      "learning_rate": 0.00015366536629729795,
      "loss": 0.0933,
      "step": 29050
    },
    {
      "epoch": 0.6964429951835343,
      "grad_norm": 0.06858386844396591,
      "learning_rate": 0.00015358558903541314,
      "loss": 0.0827,
      "step": 29100
    },
    {
      "epoch": 0.6976396326323032,
      "grad_norm": 0.06867150962352753,
      "learning_rate": 0.00015350581177352832,
      "loss": 0.0875,
      "step": 29150
    },
    {
      "epoch": 0.6988362700810722,
      "grad_norm": 0.047329921275377274,
      "learning_rate": 0.0001534260345116435,
      "loss": 0.089,
      "step": 29200
    },
    {
      "epoch": 0.7000329075298412,
      "grad_norm": 0.07308631390333176,
      "learning_rate": 0.0001533462572497587,
      "loss": 0.0871,
      "step": 29250
    },
    {
      "epoch": 0.7012295449786101,
      "grad_norm": 0.08260912448167801,
      "learning_rate": 0.00015326807553311155,
      "loss": 0.0875,
      "step": 29300
    },
    {
      "epoch": 0.7024261824273791,
      "grad_norm": 0.07140029221773148,
      "learning_rate": 0.00015318829827122674,
      "loss": 0.0881,
      "step": 29350
    },
    {
      "epoch": 0.703622819876148,
      "grad_norm": 0.08064645528793335,
      "learning_rate": 0.00015310852100934192,
      "loss": 0.0894,
      "step": 29400
    },
    {
      "epoch": 0.704819457324917,
      "grad_norm": NaN,
      "learning_rate": 0.00015303033929269481,
      "loss": 0.091,
      "step": 29450
    },
    {
      "epoch": 0.706016094773686,
      "grad_norm": 0.05198565125465393,
      "learning_rate": 0.00015295215757604768,
      "loss": 0.0837,
      "step": 29500
    },
    {
      "epoch": 0.707212732222455,
      "grad_norm": 0.06780914962291718,
      "learning_rate": 0.00015287238031416286,
      "loss": 0.086,
      "step": 29550
    },
    {
      "epoch": 0.7084093696712238,
      "grad_norm": 0.06478274613618851,
      "learning_rate": 0.00015279260305227805,
      "loss": 0.0876,
      "step": 29600
    },
    {
      "epoch": 0.7096060071199928,
      "grad_norm": 0.06523337960243225,
      "learning_rate": 0.00015271282579039323,
      "loss": 0.0862,
      "step": 29650
    },
    {
      "epoch": 0.7108026445687617,
      "grad_norm": 0.06699363887310028,
      "learning_rate": 0.00015263304852850841,
      "loss": 0.0861,
      "step": 29700
    },
    {
      "epoch": 0.7119992820175307,
      "grad_norm": 0.08698002994060516,
      "learning_rate": 0.0001525532712666236,
      "loss": 0.0831,
      "step": 29750
    },
    {
      "epoch": 0.7131959194662997,
      "grad_norm": 0.06726640462875366,
      "learning_rate": 0.00015247349400473878,
      "loss": 0.0857,
      "step": 29800
    },
    {
      "epoch": 0.7143925569150686,
      "grad_norm": 0.043019864708185196,
      "learning_rate": 0.00015239371674285397,
      "loss": 0.0898,
      "step": 29850
    },
    {
      "epoch": 0.7155891943638376,
      "grad_norm": 0.06765254586935043,
      "learning_rate": 0.00015231393948096915,
      "loss": 0.0858,
      "step": 29900
    },
    {
      "epoch": 0.7167858318126066,
      "grad_norm": 0.08980010449886322,
      "learning_rate": 0.00015223416221908434,
      "loss": 0.0897,
      "step": 29950
    },
    {
      "epoch": 0.7179824692613755,
      "grad_norm": 0.06485816836357117,
      "learning_rate": 0.00015215438495719952,
      "loss": 0.0877,
      "step": 30000
    },
    {
      "epoch": 0.7191791067101445,
      "grad_norm": 0.051472827792167664,
      "learning_rate": 0.0001520746076953147,
      "loss": 0.0849,
      "step": 30050
    },
    {
      "epoch": 0.7203757441589135,
      "grad_norm": 0.050480734556913376,
      "learning_rate": 0.0001519948304334299,
      "loss": 0.084,
      "step": 30100
    },
    {
      "epoch": 0.7215723816076824,
      "grad_norm": 0.09672082960605621,
      "learning_rate": 0.00015191505317154507,
      "loss": 0.0856,
      "step": 30150
    },
    {
      "epoch": 0.7227690190564514,
      "grad_norm": 0.06553083658218384,
      "learning_rate": 0.00015183527590966026,
      "loss": 0.0874,
      "step": 30200
    },
    {
      "epoch": 0.7239656565052204,
      "grad_norm": 0.06697530299425125,
      "learning_rate": 0.00015175549864777544,
      "loss": 0.0839,
      "step": 30250
    },
    {
      "epoch": 0.7251622939539893,
      "grad_norm": 0.053623903542757034,
      "learning_rate": 0.0001516757213858906,
      "loss": 0.0837,
      "step": 30300
    },
    {
      "epoch": 0.7263589314027582,
      "grad_norm": 0.06629790365695953,
      "learning_rate": 0.00015159594412400578,
      "loss": 0.0871,
      "step": 30350
    },
    {
      "epoch": 0.7275555688515272,
      "grad_norm": 0.044252149760723114,
      "learning_rate": 0.00015151616686212097,
      "loss": 0.088,
      "step": 30400
    },
    {
      "epoch": 0.7287522063002961,
      "grad_norm": 0.10516753792762756,
      "learning_rate": 0.00015143638960023615,
      "loss": 0.0838,
      "step": 30450
    },
    {
      "epoch": 0.7299488437490651,
      "grad_norm": 0.06357888877391815,
      "learning_rate": 0.00015135661233835134,
      "loss": 0.0844,
      "step": 30500
    },
    {
      "epoch": 0.7311454811978341,
      "grad_norm": 0.06259555369615555,
      "learning_rate": 0.0001512768350764665,
      "loss": 0.0824,
      "step": 30550
    },
    {
      "epoch": 0.732342118646603,
      "grad_norm": 0.0467740036547184,
      "learning_rate": 0.00015119705781458168,
      "loss": 0.0804,
      "step": 30600
    },
    {
      "epoch": 0.733538756095372,
      "grad_norm": 0.049099236726760864,
      "learning_rate": 0.00015111728055269686,
      "loss": 0.0889,
      "step": 30650
    },
    {
      "epoch": 0.734735393544141,
      "grad_norm": 0.06401202827692032,
      "learning_rate": 0.00015103750329081205,
      "loss": 0.0856,
      "step": 30700
    },
    {
      "epoch": 0.7359320309929099,
      "grad_norm": 0.09054817259311676,
      "learning_rate": 0.00015095772602892723,
      "loss": 0.0899,
      "step": 30750
    },
    {
      "epoch": 0.7371286684416789,
      "grad_norm": 0.09614186733961105,
      "learning_rate": 0.00015087794876704241,
      "loss": 0.0868,
      "step": 30800
    },
    {
      "epoch": 0.7383253058904479,
      "grad_norm": 0.05264759063720703,
      "learning_rate": 0.0001507981715051576,
      "loss": 0.0867,
      "step": 30850
    },
    {
      "epoch": 0.7395219433392168,
      "grad_norm": 0.09620338678359985,
      "learning_rate": 0.00015071839424327278,
      "loss": 0.083,
      "step": 30900
    },
    {
      "epoch": 0.7407185807879858,
      "grad_norm": 0.06550569087266922,
      "learning_rate": 0.00015063861698138797,
      "loss": 0.0884,
      "step": 30950
    },
    {
      "epoch": 0.7419152182367548,
      "grad_norm": 0.05636286735534668,
      "learning_rate": 0.00015055883971950315,
      "loss": 0.085,
      "step": 31000
    },
    {
      "epoch": 0.7431118556855236,
      "grad_norm": 0.07503238320350647,
      "learning_rate": 0.00015047906245761834,
      "loss": 0.0857,
      "step": 31050
    },
    {
      "epoch": 0.7443084931342926,
      "grad_norm": 0.1237107664346695,
      "learning_rate": 0.00015039928519573352,
      "loss": 0.084,
      "step": 31100
    },
    {
      "epoch": 0.7455051305830616,
      "grad_norm": 0.06393103301525116,
      "learning_rate": 0.0001503195079338487,
      "loss": 0.0841,
      "step": 31150
    },
    {
      "epoch": 0.7467017680318305,
      "grad_norm": 0.06655029952526093,
      "learning_rate": 0.0001502397306719639,
      "loss": 0.0857,
      "step": 31200
    },
    {
      "epoch": 0.7478984054805995,
      "grad_norm": 0.07022928446531296,
      "learning_rate": 0.00015015995341007907,
      "loss": 0.0836,
      "step": 31250
    },
    {
      "epoch": 0.7490950429293685,
      "grad_norm": 0.05477366968989372,
      "learning_rate": 0.00015008017614819426,
      "loss": 0.0861,
      "step": 31300
    },
    {
      "epoch": 0.7502916803781374,
      "grad_norm": 0.08062362670898438,
      "learning_rate": 0.00015000039888630944,
      "loss": 0.0849,
      "step": 31350
    },
    {
      "epoch": 0.7514883178269064,
      "grad_norm": 0.05833959951996803,
      "learning_rate": 0.00014992062162442462,
      "loss": 0.083,
      "step": 31400
    },
    {
      "epoch": 0.7526849552756754,
      "grad_norm": 0.06975274533033371,
      "learning_rate": 0.0001498408443625398,
      "loss": 0.0875,
      "step": 31450
    },
    {
      "epoch": 0.7538815927244443,
      "grad_norm": 0.05999016389250755,
      "learning_rate": 0.00014976266264589267,
      "loss": 0.0855,
      "step": 31500
    },
    {
      "epoch": 0.7550782301732133,
      "grad_norm": 0.04039478674530983,
      "learning_rate": 0.00014968288538400786,
      "loss": 0.0851,
      "step": 31550
    },
    {
      "epoch": 0.7562748676219823,
      "grad_norm": 0.06213688477873802,
      "learning_rate": 0.00014960310812212304,
      "loss": 0.0843,
      "step": 31600
    },
    {
      "epoch": 0.7574715050707512,
      "grad_norm": 0.07234949618577957,
      "learning_rate": 0.00014952333086023823,
      "loss": 0.0884,
      "step": 31650
    },
    {
      "epoch": 0.7586681425195202,
      "grad_norm": 0.08464519679546356,
      "learning_rate": 0.0001494435535983534,
      "loss": 0.0885,
      "step": 31700
    },
    {
      "epoch": 0.7598647799682892,
      "grad_norm": 0.09024342149496078,
      "learning_rate": 0.0001493637763364686,
      "loss": 0.0907,
      "step": 31750
    },
    {
      "epoch": 0.761061417417058,
      "grad_norm": 0.061060529202222824,
      "learning_rate": 0.00014928399907458378,
      "loss": 0.0837,
      "step": 31800
    },
    {
      "epoch": 0.762258054865827,
      "grad_norm": 0.0764414370059967,
      "learning_rate": 0.00014920422181269896,
      "loss": 0.0872,
      "step": 31850
    },
    {
      "epoch": 0.763454692314596,
      "grad_norm": 0.06444203108549118,
      "learning_rate": 0.00014912444455081415,
      "loss": 0.0852,
      "step": 31900
    },
    {
      "epoch": 0.7646513297633649,
      "grad_norm": 0.057286325842142105,
      "learning_rate": 0.00014904466728892933,
      "loss": 0.083,
      "step": 31950
    },
    {
      "epoch": 0.7658479672121339,
      "grad_norm": 0.0602886937558651,
      "learning_rate": 0.0001489648900270445,
      "loss": 0.0842,
      "step": 32000
    },
    {
      "epoch": 0.7670446046609029,
      "grad_norm": 0.11444523185491562,
      "learning_rate": 0.00014888511276515967,
      "loss": 0.0843,
      "step": 32050
    },
    {
      "epoch": 0.7682412421096718,
      "grad_norm": 0.10373920202255249,
      "learning_rate": 0.00014880533550327486,
      "loss": 0.0884,
      "step": 32100
    },
    {
      "epoch": 0.7694378795584408,
      "grad_norm": 0.06320834159851074,
      "learning_rate": 0.00014872555824139004,
      "loss": 0.0882,
      "step": 32150
    },
    {
      "epoch": 0.7706345170072098,
      "grad_norm": 0.06067259982228279,
      "learning_rate": 0.00014864578097950523,
      "loss": 0.0843,
      "step": 32200
    },
    {
      "epoch": 0.7718311544559787,
      "grad_norm": 0.06392174959182739,
      "learning_rate": 0.0001485660037176204,
      "loss": 0.0877,
      "step": 32250
    },
    {
      "epoch": 0.7730277919047477,
      "grad_norm": 0.0620342381298542,
      "learning_rate": 0.0001484862264557356,
      "loss": 0.0855,
      "step": 32300
    },
    {
      "epoch": 0.7742244293535167,
      "grad_norm": 0.06701412796974182,
      "learning_rate": 0.00014840644919385078,
      "loss": 0.0814,
      "step": 32350
    },
    {
      "epoch": 0.7754210668022856,
      "grad_norm": 0.07451263815164566,
      "learning_rate": 0.00014832667193196596,
      "loss": 0.0831,
      "step": 32400
    },
    {
      "epoch": 0.7766177042510546,
      "grad_norm": 0.11178869754076004,
      "learning_rate": 0.00014824689467008115,
      "loss": 0.0824,
      "step": 32450
    },
    {
      "epoch": 0.7778143416998234,
      "grad_norm": 0.08450697362422943,
      "learning_rate": 0.00014816711740819633,
      "loss": 0.087,
      "step": 32500
    },
    {
      "epoch": 0.7790109791485924,
      "grad_norm": 0.06112925708293915,
      "learning_rate": 0.00014808734014631151,
      "loss": 0.0836,
      "step": 32550
    },
    {
      "epoch": 0.7802076165973614,
      "grad_norm": 0.07195156067609787,
      "learning_rate": 0.0001480075628844267,
      "loss": 0.0895,
      "step": 32600
    },
    {
      "epoch": 0.7814042540461303,
      "grad_norm": 0.056621652096509933,
      "learning_rate": 0.00014792778562254188,
      "loss": 0.0849,
      "step": 32650
    },
    {
      "epoch": 0.7826008914948993,
      "grad_norm": 0.040775738656520844,
      "learning_rate": 0.00014784800836065704,
      "loss": 0.0843,
      "step": 32700
    },
    {
      "epoch": 0.7837975289436683,
      "grad_norm": 0.07058610022068024,
      "learning_rate": 0.00014776823109877222,
      "loss": 0.0853,
      "step": 32750
    },
    {
      "epoch": 0.7849941663924372,
      "grad_norm": 0.07336518168449402,
      "learning_rate": 0.0001476884538368874,
      "loss": 0.0842,
      "step": 32800
    },
    {
      "epoch": 0.7861908038412062,
      "grad_norm": 0.05881037190556526,
      "learning_rate": 0.0001476086765750026,
      "loss": 0.0858,
      "step": 32850
    },
    {
      "epoch": 0.7873874412899752,
      "grad_norm": 0.07624153792858124,
      "learning_rate": 0.00014752889931311778,
      "loss": 0.0873,
      "step": 32900
    },
    {
      "epoch": 0.7885840787387441,
      "grad_norm": 0.04547615349292755,
      "learning_rate": 0.00014744912205123296,
      "loss": 0.0826,
      "step": 32950
    },
    {
      "epoch": 0.7897807161875131,
      "grad_norm": 0.10399945825338364,
      "learning_rate": 0.00014736934478934815,
      "loss": 0.0873,
      "step": 33000
    },
    {
      "epoch": 0.7909773536362821,
      "grad_norm": 0.08143378049135208,
      "learning_rate": 0.00014728956752746333,
      "loss": 0.083,
      "step": 33050
    },
    {
      "epoch": 0.792173991085051,
      "grad_norm": 0.0598541721701622,
      "learning_rate": 0.00014720979026557851,
      "loss": 0.0818,
      "step": 33100
    },
    {
      "epoch": 0.79337062853382,
      "grad_norm": 0.052055008709430695,
      "learning_rate": 0.0001471300130036937,
      "loss": 0.0897,
      "step": 33150
    },
    {
      "epoch": 0.794567265982589,
      "grad_norm": 0.07728110998868942,
      "learning_rate": 0.00014705023574180888,
      "loss": 0.0918,
      "step": 33200
    },
    {
      "epoch": 0.7957639034313578,
      "grad_norm": 0.08553159236907959,
      "learning_rate": 0.00014697045847992407,
      "loss": 0.0868,
      "step": 33250
    },
    {
      "epoch": 0.7969605408801268,
      "grad_norm": 0.0818668082356453,
      "learning_rate": 0.00014689068121803925,
      "loss": 0.0875,
      "step": 33300
    },
    {
      "epoch": 0.7981571783288958,
      "grad_norm": 0.05327269807457924,
      "learning_rate": 0.0001468109039561544,
      "loss": 0.082,
      "step": 33350
    },
    {
      "epoch": 0.7993538157776647,
      "grad_norm": 0.05822485312819481,
      "learning_rate": 0.0001467311266942696,
      "loss": 0.0849,
      "step": 33400
    },
    {
      "epoch": 0.8005504532264337,
      "grad_norm": 0.06928814202547073,
      "learning_rate": 0.00014665134943238478,
      "loss": 0.0871,
      "step": 33450
    },
    {
      "epoch": 0.8017470906752027,
      "grad_norm": 0.08791732043027878,
      "learning_rate": 0.00014657157217049996,
      "loss": 0.0835,
      "step": 33500
    },
    {
      "epoch": 0.8029437281239716,
      "grad_norm": 0.046267069876194,
      "learning_rate": 0.00014649179490861515,
      "loss": 0.0854,
      "step": 33550
    },
    {
      "epoch": 0.8041403655727406,
      "grad_norm": 0.05996611341834068,
      "learning_rate": 0.00014641201764673033,
      "loss": 0.0848,
      "step": 33600
    },
    {
      "epoch": 0.8053370030215096,
      "grad_norm": 0.03786373883485794,
      "learning_rate": 0.00014633224038484551,
      "loss": 0.086,
      "step": 33650
    },
    {
      "epoch": 0.8065336404702785,
      "grad_norm": 0.04937741160392761,
      "learning_rate": 0.0001462524631229607,
      "loss": 0.0862,
      "step": 33700
    },
    {
      "epoch": 0.8077302779190475,
      "grad_norm": 0.07111271470785141,
      "learning_rate": 0.00014617268586107588,
      "loss": 0.0859,
      "step": 33750
    },
    {
      "epoch": 0.8089269153678165,
      "grad_norm": 0.04160083830356598,
      "learning_rate": 0.00014609290859919107,
      "loss": 0.0873,
      "step": 33800
    },
    {
      "epoch": 0.8101235528165854,
      "grad_norm": 0.052206676453351974,
      "learning_rate": 0.00014601313133730625,
      "loss": 0.084,
      "step": 33850
    },
    {
      "epoch": 0.8113201902653544,
      "grad_norm": 0.04695536196231842,
      "learning_rate": 0.00014593335407542144,
      "loss": 0.0823,
      "step": 33900
    },
    {
      "epoch": 0.8125168277141234,
      "grad_norm": 0.06659168750047684,
      "learning_rate": 0.00014585357681353662,
      "loss": 0.0831,
      "step": 33950
    },
    {
      "epoch": 0.8137134651628922,
      "grad_norm": 0.07025635987520218,
      "learning_rate": 0.0001457737995516518,
      "loss": 0.0836,
      "step": 34000
    },
    {
      "epoch": 0.8149101026116612,
      "grad_norm": 0.064022496342659,
      "learning_rate": 0.000145694022289767,
      "loss": 0.0873,
      "step": 34050
    },
    {
      "epoch": 0.8161067400604302,
      "grad_norm": 0.07394794374704361,
      "learning_rate": 0.00014561424502788217,
      "loss": 0.0868,
      "step": 34100
    },
    {
      "epoch": 0.8173033775091991,
      "grad_norm": 0.09425968676805496,
      "learning_rate": 0.00014553446776599736,
      "loss": 0.0887,
      "step": 34150
    },
    {
      "epoch": 0.8185000149579681,
      "grad_norm": 0.06078237295150757,
      "learning_rate": 0.00014545469050411254,
      "loss": 0.0848,
      "step": 34200
    },
    {
      "epoch": 0.8196966524067371,
      "grad_norm": 0.041816119104623795,
      "learning_rate": 0.00014537491324222772,
      "loss": 0.0851,
      "step": 34250
    },
    {
      "epoch": 0.820893289855506,
      "grad_norm": 0.06375802308320999,
      "learning_rate": 0.0001452951359803429,
      "loss": 0.0795,
      "step": 34300
    },
    {
      "epoch": 0.822089927304275,
      "grad_norm": 0.05728929862380028,
      "learning_rate": 0.00014521535871845807,
      "loss": 0.087,
      "step": 34350
    },
    {
      "epoch": 0.823286564753044,
      "grad_norm": 0.07949934899806976,
      "learning_rate": 0.00014513558145657325,
      "loss": 0.0867,
      "step": 34400
    },
    {
      "epoch": 0.8244832022018129,
      "grad_norm": 0.07798270136117935,
      "learning_rate": 0.00014505580419468843,
      "loss": 0.0894,
      "step": 34450
    },
    {
      "epoch": 0.8256798396505819,
      "grad_norm": 0.08409100770950317,
      "learning_rate": 0.00014497602693280362,
      "loss": 0.0856,
      "step": 34500
    },
    {
      "epoch": 0.8268764770993509,
      "grad_norm": 0.05822085216641426,
      "learning_rate": 0.0001448962496709188,
      "loss": 0.0814,
      "step": 34550
    },
    {
      "epoch": 0.8280731145481198,
      "grad_norm": 0.0789986401796341,
      "learning_rate": 0.000144816472409034,
      "loss": 0.0856,
      "step": 34600
    },
    {
      "epoch": 0.8292697519968888,
      "grad_norm": 0.05898085981607437,
      "learning_rate": 0.00014473669514714917,
      "loss": 0.0834,
      "step": 34650
    },
    {
      "epoch": 0.8304663894456576,
      "grad_norm": 0.042349543422460556,
      "learning_rate": 0.00014465691788526436,
      "loss": 0.0812,
      "step": 34700
    },
    {
      "epoch": 0.8316630268944266,
      "grad_norm": 0.07518187910318375,
      "learning_rate": 0.0001445771406233795,
      "loss": 0.0866,
      "step": 34750
    },
    {
      "epoch": 0.8328596643431956,
      "grad_norm": 0.047830235213041306,
      "learning_rate": 0.0001444973633614947,
      "loss": 0.0838,
      "step": 34800
    },
    {
      "epoch": 0.8340563017919645,
      "grad_norm": 0.0592980720102787,
      "learning_rate": 0.00014441758609960988,
      "loss": 0.0851,
      "step": 34850
    },
    {
      "epoch": 0.8352529392407335,
      "grad_norm": 0.05041862651705742,
      "learning_rate": 0.00014433780883772507,
      "loss": 0.0835,
      "step": 34900
    },
    {
      "epoch": 0.8364495766895025,
      "grad_norm": 0.07793822884559631,
      "learning_rate": 0.00014425803157584025,
      "loss": 0.0928,
      "step": 34950
    },
    {
      "epoch": 0.8376462141382714,
      "grad_norm": 0.0727623924612999,
      "learning_rate": 0.00014417825431395543,
      "loss": 0.0895,
      "step": 35000
    },
    {
      "epoch": 0.8388428515870404,
      "grad_norm": 0.043557099997997284,
      "learning_rate": 0.00014409847705207062,
      "loss": 0.0889,
      "step": 35050
    },
    {
      "epoch": 0.8400394890358094,
      "grad_norm": 0.06430898606777191,
      "learning_rate": 0.0001440186997901858,
      "loss": 0.0815,
      "step": 35100
    },
    {
      "epoch": 0.8412361264845784,
      "grad_norm": 0.0919443815946579,
      "learning_rate": 0.000143938922528301,
      "loss": 0.091,
      "step": 35150
    },
    {
      "epoch": 0.8424327639333473,
      "grad_norm": 0.05446472764015198,
      "learning_rate": 0.00014385914526641617,
      "loss": 0.0846,
      "step": 35200
    },
    {
      "epoch": 0.8436294013821163,
      "grad_norm": 0.06268782168626785,
      "learning_rate": 0.00014377936800453136,
      "loss": 0.0868,
      "step": 35250
    },
    {
      "epoch": 0.8448260388308853,
      "grad_norm": 0.05619369447231293,
      "learning_rate": 0.00014369959074264654,
      "loss": 0.0842,
      "step": 35300
    },
    {
      "epoch": 0.8460226762796542,
      "grad_norm": 0.0698886290192604,
      "learning_rate": 0.00014361981348076172,
      "loss": 0.0816,
      "step": 35350
    },
    {
      "epoch": 0.8472193137284232,
      "grad_norm": 0.07408277690410614,
      "learning_rate": 0.0001435400362188769,
      "loss": 0.0888,
      "step": 35400
    },
    {
      "epoch": 0.848415951177192,
      "grad_norm": 0.058750685304403305,
      "learning_rate": 0.0001434602589569921,
      "loss": 0.0861,
      "step": 35450
    },
    {
      "epoch": 0.849612588625961,
      "grad_norm": 0.07452738285064697,
      "learning_rate": 0.00014338048169510728,
      "loss": 0.0829,
      "step": 35500
    },
    {
      "epoch": 0.85080922607473,
      "grad_norm": 0.08680198341608047,
      "learning_rate": 0.00014330070443322246,
      "loss": 0.0801,
      "step": 35550
    },
    {
      "epoch": 0.8520058635234989,
      "grad_norm": 0.06149350106716156,
      "learning_rate": 0.00014322092717133765,
      "loss": 0.0867,
      "step": 35600
    },
    {
      "epoch": 0.8532025009722679,
      "grad_norm": 0.062022868543863297,
      "learning_rate": 0.00014314114990945283,
      "loss": 0.0912,
      "step": 35650
    },
    {
      "epoch": 0.8543991384210369,
      "grad_norm": 0.06001749262213707,
      "learning_rate": 0.000143061372647568,
      "loss": 0.0838,
      "step": 35700
    },
    {
      "epoch": 0.8555957758698058,
      "grad_norm": 0.05156748741865158,
      "learning_rate": 0.0001429815953856832,
      "loss": 0.0819,
      "step": 35750
    },
    {
      "epoch": 0.8567924133185748,
      "grad_norm": 0.07641961425542831,
      "learning_rate": 0.00014290181812379838,
      "loss": 0.087,
      "step": 35800
    },
    {
      "epoch": 0.8579890507673438,
      "grad_norm": 0.13401512801647186,
      "learning_rate": 0.00014282204086191357,
      "loss": 0.0834,
      "step": 35850
    },
    {
      "epoch": 0.8591856882161127,
      "grad_norm": 0.0654861107468605,
      "learning_rate": 0.00014274226360002872,
      "loss": 0.0834,
      "step": 35900
    },
    {
      "epoch": 0.8603823256648817,
      "grad_norm": 0.0729140192270279,
      "learning_rate": 0.0001426624863381439,
      "loss": 0.0849,
      "step": 35950
    },
    {
      "epoch": 0.8615789631136507,
      "grad_norm": 0.05441085994243622,
      "learning_rate": 0.0001425827090762591,
      "loss": 0.0848,
      "step": 36000
    },
    {
      "epoch": 0.8627756005624196,
      "grad_norm": 0.08549844473600388,
      "learning_rate": 0.00014250293181437428,
      "loss": 0.0849,
      "step": 36050
    },
    {
      "epoch": 0.8639722380111886,
      "grad_norm": 0.05666779354214668,
      "learning_rate": 0.00014242315455248943,
      "loss": 0.0876,
      "step": 36100
    },
    {
      "epoch": 0.8651688754599575,
      "grad_norm": 0.09193292260169983,
      "learning_rate": 0.00014234337729060462,
      "loss": 0.0819,
      "step": 36150
    },
    {
      "epoch": 0.8663655129087264,
      "grad_norm": 0.06554559618234634,
      "learning_rate": 0.0001422636000287198,
      "loss": 0.0816,
      "step": 36200
    },
    {
      "epoch": 0.8675621503574954,
      "grad_norm": 0.08466874808073044,
      "learning_rate": 0.00014218382276683499,
      "loss": 0.0895,
      "step": 36250
    },
    {
      "epoch": 0.8687587878062644,
      "grad_norm": 0.11803454905748367,
      "learning_rate": 0.00014210404550495017,
      "loss": 0.0857,
      "step": 36300
    },
    {
      "epoch": 0.8699554252550333,
      "grad_norm": 0.11225708574056625,
      "learning_rate": 0.00014202426824306535,
      "loss": 0.0862,
      "step": 36350
    },
    {
      "epoch": 0.8711520627038023,
      "grad_norm": 0.05666003376245499,
      "learning_rate": 0.00014194449098118054,
      "loss": 0.0836,
      "step": 36400
    },
    {
      "epoch": 0.8723487001525713,
      "grad_norm": 0.13633394241333008,
      "learning_rate": 0.00014186471371929572,
      "loss": 0.09,
      "step": 36450
    },
    {
      "epoch": 0.8735453376013402,
      "grad_norm": 0.06478317081928253,
      "learning_rate": 0.0001417849364574109,
      "loss": 0.0847,
      "step": 36500
    },
    {
      "epoch": 0.8747419750501092,
      "grad_norm": 0.058281391859054565,
      "learning_rate": 0.0001417051591955261,
      "loss": 0.083,
      "step": 36550
    },
    {
      "epoch": 0.8759386124988782,
      "grad_norm": 0.0893142968416214,
      "learning_rate": 0.00014162538193364128,
      "loss": 0.0863,
      "step": 36600
    },
    {
      "epoch": 0.8771352499476471,
      "grad_norm": 0.05596867576241493,
      "learning_rate": 0.00014154560467175646,
      "loss": 0.0812,
      "step": 36650
    },
    {
      "epoch": 0.8783318873964161,
      "grad_norm": 0.059767551720142365,
      "learning_rate": 0.00014146582740987164,
      "loss": 0.085,
      "step": 36700
    },
    {
      "epoch": 0.8795285248451851,
      "grad_norm": 0.05283380672335625,
      "learning_rate": 0.00014138605014798683,
      "loss": 0.0825,
      "step": 36750
    },
    {
      "epoch": 0.880725162293954,
      "grad_norm": 0.07911880314350128,
      "learning_rate": 0.000141306272886102,
      "loss": 0.0833,
      "step": 36800
    },
    {
      "epoch": 0.881921799742723,
      "grad_norm": 0.07529754936695099,
      "learning_rate": 0.0001412264956242172,
      "loss": 0.0816,
      "step": 36850
    },
    {
      "epoch": 0.8831184371914919,
      "grad_norm": 0.07605848461389542,
      "learning_rate": 0.00014114671836233238,
      "loss": 0.0856,
      "step": 36900
    },
    {
      "epoch": 0.8843150746402608,
      "grad_norm": 0.07010654360055923,
      "learning_rate": 0.00014106694110044757,
      "loss": 0.086,
      "step": 36950
    },
    {
      "epoch": 0.8855117120890298,
      "grad_norm": 0.0979762151837349,
      "learning_rate": 0.00014098716383856275,
      "loss": 0.0835,
      "step": 37000
    },
    {
      "epoch": 0.8867083495377988,
      "grad_norm": 0.049322884529829025,
      "learning_rate": 0.00014090738657667793,
      "loss": 0.0897,
      "step": 37050
    },
    {
      "epoch": 0.8879049869865677,
      "grad_norm": 0.08002061396837234,
      "learning_rate": 0.00014082760931479312,
      "loss": 0.0809,
      "step": 37100
    },
    {
      "epoch": 0.8891016244353367,
      "grad_norm": 0.07418494671583176,
      "learning_rate": 0.0001407478320529083,
      "loss": 0.0803,
      "step": 37150
    },
    {
      "epoch": 0.8902982618841057,
      "grad_norm": 0.05787598714232445,
      "learning_rate": 0.0001406680547910235,
      "loss": 0.0866,
      "step": 37200
    },
    {
      "epoch": 0.8914948993328746,
      "grad_norm": 0.07319840043783188,
      "learning_rate": 0.00014058827752913864,
      "loss": 0.0861,
      "step": 37250
    },
    {
      "epoch": 0.8926915367816436,
      "grad_norm": 0.08913751691579819,
      "learning_rate": 0.00014050850026725383,
      "loss": 0.0853,
      "step": 37300
    },
    {
      "epoch": 0.8938881742304126,
      "grad_norm": 0.07509776949882507,
      "learning_rate": 0.000140428723005369,
      "loss": 0.0842,
      "step": 37350
    },
    {
      "epoch": 0.8950848116791815,
      "grad_norm": 0.06633678823709488,
      "learning_rate": 0.0001403489457434842,
      "loss": 0.084,
      "step": 37400
    },
    {
      "epoch": 0.8962814491279505,
      "grad_norm": 0.06158293038606644,
      "learning_rate": 0.00014026916848159938,
      "loss": 0.0811,
      "step": 37450
    },
    {
      "epoch": 0.8974780865767195,
      "grad_norm": 0.05692153796553612,
      "learning_rate": 0.00014018939121971456,
      "loss": 0.0847,
      "step": 37500
    },
    {
      "epoch": 0.8986747240254884,
      "grad_norm": 0.06176559254527092,
      "learning_rate": 0.00014010961395782975,
      "loss": 0.085,
      "step": 37550
    },
    {
      "epoch": 0.8998713614742574,
      "grad_norm": 0.05839860439300537,
      "learning_rate": 0.00014002983669594493,
      "loss": 0.0786,
      "step": 37600
    },
    {
      "epoch": 0.9010679989230262,
      "grad_norm": 0.05669102817773819,
      "learning_rate": 0.00013995005943406012,
      "loss": 0.0885,
      "step": 37650
    },
    {
      "epoch": 0.9022646363717952,
      "grad_norm": 0.08042043447494507,
      "learning_rate": 0.0001398702821721753,
      "loss": 0.0815,
      "step": 37700
    },
    {
      "epoch": 0.9034612738205642,
      "grad_norm": 0.05315053090453148,
      "learning_rate": 0.00013979050491029046,
      "loss": 0.0862,
      "step": 37750
    },
    {
      "epoch": 0.9046579112693331,
      "grad_norm": 0.05522051826119423,
      "learning_rate": 0.00013971072764840564,
      "loss": 0.0831,
      "step": 37800
    },
    {
      "epoch": 0.9058545487181021,
      "grad_norm": 0.04244663193821907,
      "learning_rate": 0.00013963095038652083,
      "loss": 0.0858,
      "step": 37850
    },
    {
      "epoch": 0.9070511861668711,
      "grad_norm": 0.08513443171977997,
      "learning_rate": 0.000139551173124636,
      "loss": 0.0834,
      "step": 37900
    },
    {
      "epoch": 0.90824782361564,
      "grad_norm": 0.07398099452257156,
      "learning_rate": 0.0001394713958627512,
      "loss": 0.086,
      "step": 37950
    },
    {
      "epoch": 0.909444461064409,
      "grad_norm": 0.058741968125104904,
      "learning_rate": 0.00013939161860086638,
      "loss": 0.0858,
      "step": 38000
    },
    {
      "epoch": 0.910641098513178,
      "grad_norm": 0.07000650465488434,
      "learning_rate": 0.00013931184133898156,
      "loss": 0.0799,
      "step": 38050
    },
    {
      "epoch": 0.911837735961947,
      "grad_norm": 0.10642658174037933,
      "learning_rate": 0.00013923206407709675,
      "loss": 0.0854,
      "step": 38100
    },
    {
      "epoch": 0.9130343734107159,
      "grad_norm": 0.08727287501096725,
      "learning_rate": 0.00013915228681521193,
      "loss": 0.0888,
      "step": 38150
    },
    {
      "epoch": 0.9142310108594849,
      "grad_norm": 0.08280196785926819,
      "learning_rate": 0.00013907250955332712,
      "loss": 0.0757,
      "step": 38200
    },
    {
      "epoch": 0.9154276483082538,
      "grad_norm": 0.048205215483903885,
      "learning_rate": 0.0001389927322914423,
      "loss": 0.0816,
      "step": 38250
    },
    {
      "epoch": 0.9166242857570228,
      "grad_norm": 0.07202233374118805,
      "learning_rate": 0.00013891295502955749,
      "loss": 0.0834,
      "step": 38300
    },
    {
      "epoch": 0.9178209232057917,
      "grad_norm": 0.04249013587832451,
      "learning_rate": 0.00013883317776767267,
      "loss": 0.086,
      "step": 38350
    },
    {
      "epoch": 0.9190175606545606,
      "grad_norm": 0.05252514034509659,
      "learning_rate": 0.00013875340050578785,
      "loss": 0.0859,
      "step": 38400
    },
    {
      "epoch": 0.9202141981033296,
      "grad_norm": 0.0739172175526619,
      "learning_rate": 0.00013867362324390304,
      "loss": 0.089,
      "step": 38450
    },
    {
      "epoch": 0.9214108355520986,
      "grad_norm": 0.045782629400491714,
      "learning_rate": 0.00013859384598201822,
      "loss": 0.0842,
      "step": 38500
    },
    {
      "epoch": 0.9226074730008675,
      "grad_norm": 0.04752040281891823,
      "learning_rate": 0.0001385140687201334,
      "loss": 0.0881,
      "step": 38550
    },
    {
      "epoch": 0.9238041104496365,
      "grad_norm": 0.053321924060583115,
      "learning_rate": 0.00013843429145824856,
      "loss": 0.0824,
      "step": 38600
    },
    {
      "epoch": 0.9250007478984055,
      "grad_norm": 0.07841939479112625,
      "learning_rate": 0.00013835451419636375,
      "loss": 0.0832,
      "step": 38650
    },
    {
      "epoch": 0.9261973853471744,
      "grad_norm": 0.07159627228975296,
      "learning_rate": 0.00013827473693447893,
      "loss": 0.0827,
      "step": 38700
    },
    {
      "epoch": 0.9273940227959434,
      "grad_norm": 0.06567169725894928,
      "learning_rate": 0.00013819655521783182,
      "loss": 0.0825,
      "step": 38750
    },
    {
      "epoch": 0.9285906602447124,
      "grad_norm": 0.07087917625904083,
      "learning_rate": 0.000138116777955947,
      "loss": 0.0854,
      "step": 38800
    },
    {
      "epoch": 0.9297872976934813,
      "grad_norm": 0.07519805431365967,
      "learning_rate": 0.0001380370006940622,
      "loss": 0.0846,
      "step": 38850
    },
    {
      "epoch": 0.9309839351422503,
      "grad_norm": 0.06384211778640747,
      "learning_rate": 0.00013795722343217738,
      "loss": 0.082,
      "step": 38900
    },
    {
      "epoch": 0.9321805725910193,
      "grad_norm": 0.04916202649474144,
      "learning_rate": 0.00013787744617029253,
      "loss": 0.0857,
      "step": 38950
    },
    {
      "epoch": 0.9333772100397882,
      "grad_norm": 0.11067382246255875,
      "learning_rate": 0.00013779766890840772,
      "loss": 0.077,
      "step": 39000
    },
    {
      "epoch": 0.9345738474885572,
      "grad_norm": 0.08167160302400589,
      "learning_rate": 0.0001377178916465229,
      "loss": 0.0829,
      "step": 39050
    },
    {
      "epoch": 0.9357704849373261,
      "grad_norm": 0.08550801128149033,
      "learning_rate": 0.00013763811438463809,
      "loss": 0.087,
      "step": 39100
    },
    {
      "epoch": 0.936967122386095,
      "grad_norm": 0.07039816677570343,
      "learning_rate": 0.00013755833712275327,
      "loss": 0.0835,
      "step": 39150
    },
    {
      "epoch": 0.938163759834864,
      "grad_norm": 0.09099690616130829,
      "learning_rate": 0.00013747855986086845,
      "loss": 0.0804,
      "step": 39200
    },
    {
      "epoch": 0.939360397283633,
      "grad_norm": 0.06846234202384949,
      "learning_rate": 0.00013739878259898364,
      "loss": 0.0862,
      "step": 39250
    },
    {
      "epoch": 0.9405570347324019,
      "grad_norm": 0.10801878571510315,
      "learning_rate": 0.00013731900533709882,
      "loss": 0.091,
      "step": 39300
    },
    {
      "epoch": 0.9417536721811709,
      "grad_norm": 0.08494756370782852,
      "learning_rate": 0.000137239228075214,
      "loss": 0.087,
      "step": 39350
    },
    {
      "epoch": 0.9429503096299399,
      "grad_norm": 0.05454552173614502,
      "learning_rate": 0.0001371594508133292,
      "loss": 0.0838,
      "step": 39400
    },
    {
      "epoch": 0.9441469470787088,
      "grad_norm": 0.05540662258863449,
      "learning_rate": 0.00013707967355144438,
      "loss": 0.0771,
      "step": 39450
    },
    {
      "epoch": 0.9453435845274778,
      "grad_norm": 0.058432791382074356,
      "learning_rate": 0.00013699989628955956,
      "loss": 0.0841,
      "step": 39500
    },
    {
      "epoch": 0.9465402219762468,
      "grad_norm": 0.07907064259052277,
      "learning_rate": 0.00013692011902767474,
      "loss": 0.0813,
      "step": 39550
    },
    {
      "epoch": 0.9477368594250157,
      "grad_norm": 0.06821243464946747,
      "learning_rate": 0.00013684034176578993,
      "loss": 0.0852,
      "step": 39600
    },
    {
      "epoch": 0.9489334968737847,
      "grad_norm": 0.12186805158853531,
      "learning_rate": 0.0001367605645039051,
      "loss": 0.0883,
      "step": 39650
    },
    {
      "epoch": 0.9501301343225537,
      "grad_norm": 0.06329679489135742,
      "learning_rate": 0.0001366807872420203,
      "loss": 0.0843,
      "step": 39700
    },
    {
      "epoch": 0.9513267717713226,
      "grad_norm": 0.0749114528298378,
      "learning_rate": 0.00013660100998013548,
      "loss": 0.0789,
      "step": 39750
    },
    {
      "epoch": 0.9525234092200915,
      "grad_norm": 0.07483214139938354,
      "learning_rate": 0.00013652123271825067,
      "loss": 0.0917,
      "step": 39800
    },
    {
      "epoch": 0.9537200466688605,
      "grad_norm": 0.07095532864332199,
      "learning_rate": 0.00013644145545636585,
      "loss": 0.0808,
      "step": 39850
    },
    {
      "epoch": 0.9549166841176294,
      "grad_norm": 0.07077024132013321,
      "learning_rate": 0.00013636167819448103,
      "loss": 0.0864,
      "step": 39900
    },
    {
      "epoch": 0.9561133215663984,
      "grad_norm": 0.07224185019731522,
      "learning_rate": 0.00013628190093259622,
      "loss": 0.0849,
      "step": 39950
    },
    {
      "epoch": 0.9573099590151674,
      "grad_norm": 0.08517637848854065,
      "learning_rate": 0.0001362021236707114,
      "loss": 0.0818,
      "step": 40000
    },
    {
      "epoch": 0.9585065964639363,
      "grad_norm": 0.05156223103404045,
      "learning_rate": 0.0001361223464088266,
      "loss": 0.0868,
      "step": 40050
    },
    {
      "epoch": 0.9597032339127053,
      "grad_norm": 0.05596189573407173,
      "learning_rate": 0.00013604256914694174,
      "loss": 0.0833,
      "step": 40100
    },
    {
      "epoch": 0.9608998713614743,
      "grad_norm": 0.06548962742090225,
      "learning_rate": 0.00013596279188505693,
      "loss": 0.0836,
      "step": 40150
    },
    {
      "epoch": 0.9620965088102432,
      "grad_norm": 0.04594046249985695,
      "learning_rate": 0.0001358830146231721,
      "loss": 0.0842,
      "step": 40200
    },
    {
      "epoch": 0.9632931462590122,
      "grad_norm": 0.06941507011651993,
      "learning_rate": 0.0001358032373612873,
      "loss": 0.0857,
      "step": 40250
    },
    {
      "epoch": 0.9644897837077812,
      "grad_norm": 0.059497982263565063,
      "learning_rate": 0.00013572346009940245,
      "loss": 0.0832,
      "step": 40300
    },
    {
      "epoch": 0.9656864211565501,
      "grad_norm": 0.08891289681196213,
      "learning_rate": 0.00013564368283751764,
      "loss": 0.0871,
      "step": 40350
    },
    {
      "epoch": 0.9668830586053191,
      "grad_norm": 0.07397884130477905,
      "learning_rate": 0.00013556390557563282,
      "loss": 0.0886,
      "step": 40400
    },
    {
      "epoch": 0.9680796960540881,
      "grad_norm": 0.05614827945828438,
      "learning_rate": 0.000135484128313748,
      "loss": 0.0853,
      "step": 40450
    },
    {
      "epoch": 0.969276333502857,
      "grad_norm": 0.04999510571360588,
      "learning_rate": 0.0001354043510518632,
      "loss": 0.0815,
      "step": 40500
    },
    {
      "epoch": 0.9704729709516259,
      "grad_norm": 0.08638972043991089,
      "learning_rate": 0.00013532457378997837,
      "loss": 0.0871,
      "step": 40550
    },
    {
      "epoch": 0.9716696084003948,
      "grad_norm": 0.04770613834261894,
      "learning_rate": 0.00013524479652809356,
      "loss": 0.0841,
      "step": 40600
    },
    {
      "epoch": 0.9728662458491638,
      "grad_norm": 0.08910943567752838,
      "learning_rate": 0.00013516501926620874,
      "loss": 0.0854,
      "step": 40650
    },
    {
      "epoch": 0.9740628832979328,
      "grad_norm": 0.09256240725517273,
      "learning_rate": 0.00013508524200432393,
      "loss": 0.0837,
      "step": 40700
    },
    {
      "epoch": 0.9752595207467017,
      "grad_norm": 0.07760117202997208,
      "learning_rate": 0.0001350054647424391,
      "loss": 0.082,
      "step": 40750
    },
    {
      "epoch": 0.9764561581954707,
      "grad_norm": 0.06953481584787369,
      "learning_rate": 0.0001349256874805543,
      "loss": 0.0803,
      "step": 40800
    },
    {
      "epoch": 0.9776527956442397,
      "grad_norm": 0.08017519861459732,
      "learning_rate": 0.00013484591021866948,
      "loss": 0.0836,
      "step": 40850
    },
    {
      "epoch": 0.9788494330930086,
      "grad_norm": 0.08498311042785645,
      "learning_rate": 0.00013476613295678466,
      "loss": 0.0868,
      "step": 40900
    },
    {
      "epoch": 0.9800460705417776,
      "grad_norm": 0.08599069714546204,
      "learning_rate": 0.00013468635569489985,
      "loss": 0.0864,
      "step": 40950
    },
    {
      "epoch": 0.9812427079905466,
      "grad_norm": 0.08460427075624466,
      "learning_rate": 0.0001346081739782527,
      "loss": 0.0844,
      "step": 41000
    },
    {
      "epoch": 0.9824393454393155,
      "grad_norm": 0.08664824068546295,
      "learning_rate": 0.0001345283967163679,
      "loss": 0.0802,
      "step": 41050
    },
    {
      "epoch": 0.9836359828880845,
      "grad_norm": 0.08465996384620667,
      "learning_rate": 0.00013444861945448308,
      "loss": 0.0809,
      "step": 41100
    },
    {
      "epoch": 0.9848326203368535,
      "grad_norm": 0.07551819086074829,
      "learning_rate": 0.00013436884219259827,
      "loss": 0.085,
      "step": 41150
    },
    {
      "epoch": 0.9860292577856224,
      "grad_norm": 0.05795674026012421,
      "learning_rate": 0.00013428906493071345,
      "loss": 0.0836,
      "step": 41200
    },
    {
      "epoch": 0.9872258952343914,
      "grad_norm": 0.0717053934931755,
      "learning_rate": 0.00013420928766882863,
      "loss": 0.0849,
      "step": 41250
    },
    {
      "epoch": 0.9884225326831603,
      "grad_norm": 0.07098951935768127,
      "learning_rate": 0.00013412951040694382,
      "loss": 0.0855,
      "step": 41300
    },
    {
      "epoch": 0.9896191701319292,
      "grad_norm": 0.07027815282344818,
      "learning_rate": 0.0001340513286902967,
      "loss": 0.081,
      "step": 41350
    },
    {
      "epoch": 0.9908158075806982,
      "grad_norm": 0.08820664882659912,
      "learning_rate": 0.0001339715514284119,
      "loss": 0.0814,
      "step": 41400
    },
    {
      "epoch": 0.9920124450294672,
      "grad_norm": 0.06494752317667007,
      "learning_rate": 0.00013389177416652708,
      "loss": 0.0864,
      "step": 41450
    },
    {
      "epoch": 0.9932090824782361,
      "grad_norm": 0.09240097552537918,
      "learning_rate": 0.00013381199690464226,
      "loss": 0.0818,
      "step": 41500
    },
    {
      "epoch": 0.9944057199270051,
      "grad_norm": 0.09011295437812805,
      "learning_rate": 0.00013373221964275742,
      "loss": 0.0866,
      "step": 41550
    },
    {
      "epoch": 0.9956023573757741,
      "grad_norm": 0.09680209308862686,
      "learning_rate": 0.0001336524423808726,
      "loss": 0.0759,
      "step": 41600
    },
    {
      "epoch": 0.996798994824543,
      "grad_norm": 0.11280860751867294,
      "learning_rate": 0.0001335726651189878,
      "loss": 0.0806,
      "step": 41650
    },
    {
      "epoch": 0.997995632273312,
      "grad_norm": 0.0589432492852211,
      "learning_rate": 0.00013349288785710297,
      "loss": 0.0826,
      "step": 41700
    },
    {
      "epoch": 0.999192269722081,
      "grad_norm": 0.057504940778017044,
      "learning_rate": 0.00013341311059521816,
      "loss": 0.0852,
      "step": 41750
    },
    {
      "epoch": 1.0004068567325815,
      "grad_norm": 0.08277804404497147,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.0845,
      "step": 41800
    },
    {
      "epoch": 1.0016034941813503,
      "grad_norm": 0.07585057616233826,
      "learning_rate": 0.00013325355607144852,
      "loss": 0.0789,
      "step": 41850
    },
    {
      "epoch": 1.0028001316301194,
      "grad_norm": 0.06320811808109283,
      "learning_rate": 0.0001331737788095637,
      "loss": 0.0783,
      "step": 41900
    },
    {
      "epoch": 1.0039967690788882,
      "grad_norm": 0.06463709473609924,
      "learning_rate": 0.0001330940015476789,
      "loss": 0.0786,
      "step": 41950
    },
    {
      "epoch": 1.0051934065276573,
      "grad_norm": 0.05173131823539734,
      "learning_rate": 0.00013301422428579408,
      "loss": 0.0839,
      "step": 42000
    }
  ],
  "logging_steps": 50,
  "max_steps": 125349,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.824457791298601e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
